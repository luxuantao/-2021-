{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "HW05_ZH.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "t_idPHxg4raT"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "34edba646d974707a2eba26d653b8b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2529a01e85744576bc03e44590cbb1ec",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1d9e2e920bfe40f984f07f09244ff605",
              "IPY_MODEL_b5d4961fb2114f139e6464d86f70063d"
            ]
          }
        },
        "2529a01e85744576bc03e44590cbb1ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d9e2e920bfe40f984f07f09244ff605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c443dbd9b8b54582a2949658bfdaa6a5",
            "_dom_classes": [],
            "description": "train epoch 1: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 798,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 798,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c4850abb8ecc433fa245a1dea12c0640"
          }
        },
        "b5d4961fb2114f139e6464d86f70063d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_feb90fa084154d6298dca215edb234c2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 798/798 [01:57&lt;00:00,  6.83it/s, loss=6.64]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae9d76b5c783458e827190be5328f877"
          }
        },
        "c443dbd9b8b54582a2949658bfdaa6a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c4850abb8ecc433fa245a1dea12c0640": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "feb90fa084154d6298dca215edb234c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae9d76b5c783458e827190be5328f877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "48f0bfe8918248f5b62495cab74aa1c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6d78428708994195ac53081902d58829",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aff3a47377a5423b8a402a0bd45b0c39",
              "IPY_MODEL_1ddac745fb0648aa8d4e19ec23d62fe9"
            ]
          }
        },
        "6d78428708994195ac53081902d58829": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aff3a47377a5423b8a402a0bd45b0c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fb71dc594353406cb89ac388444283fb",
            "_dom_classes": [],
            "description": "validation: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 23,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 23,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_11035c3f04f946198117493c362acf5d"
          }
        },
        "1ddac745fb0648aa8d4e19ec23d62fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_32c1e127f70f4cd88f79005ffa74fb96",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 23/23 [00:23&lt;00:00,  1.17s/it, valid_loss=7.19]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6aafc63cf2c44150b104d3b6687a9e44"
          }
        },
        "fb71dc594353406cb89ac388444283fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "11035c3f04f946198117493c362acf5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32c1e127f70f4cd88f79005ffa74fb96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6aafc63cf2c44150b104d3b6687a9e44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6eabcbd9923047daa138479dcae0b848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_45f39f1ac3784453ac13f54a7b2d83f9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ae3f0f757f2b4e13a44262f2312878be",
              "IPY_MODEL_534f2cf8702545dd8d12d574b66dec8a"
            ]
          }
        },
        "45f39f1ac3784453ac13f54a7b2d83f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae3f0f757f2b4e13a44262f2312878be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d128af55cabe4cc18701c2d9c2ef9530",
            "_dom_classes": [],
            "description": "train epoch 2: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 798,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 798,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_00282f7605464657916f3f4f336315a6"
          }
        },
        "534f2cf8702545dd8d12d574b66dec8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3716528720834940b1f57f4e0c0a5b16",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 798/798 [02:00&lt;00:00,  7.15it/s, loss=6.3]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_35dd289ac1da43b8a5a26ac1a44bba5f"
          }
        },
        "d128af55cabe4cc18701c2d9c2ef9530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "00282f7605464657916f3f4f336315a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3716528720834940b1f57f4e0c0a5b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "35dd289ac1da43b8a5a26ac1a44bba5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63d26e73c0954ebaa336d331fa042f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1ff55dff1d5e4fee96c3ef30370c1217",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7ea2d830f06341e7b80553bf437b3ba6",
              "IPY_MODEL_60ec6ff57155459e8cdf31b734d20e19"
            ]
          }
        },
        "1ff55dff1d5e4fee96c3ef30370c1217": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ea2d830f06341e7b80553bf437b3ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_68849516a44f458e8aaa5518f8c5492e",
            "_dom_classes": [],
            "description": "validation: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 23,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 23,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_89b0df52f69241508d209706297cd9ae"
          }
        },
        "60ec6ff57155459e8cdf31b734d20e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_87518f4fe1d6427589ac902375e3b17f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 23/23 [00:18&lt;00:00,  1.18it/s, valid_loss=6.61]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6d4e78504b1424392bda8bce2c891b9"
          }
        },
        "68849516a44f458e8aaa5518f8c5492e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "89b0df52f69241508d209706297cd9ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87518f4fe1d6427589ac902375e3b17f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6d4e78504b1424392bda8bce2c891b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55a8b17236c04dacb01df368edcb8d29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9111c9cfadf54bd29c9001b5b095c038",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_80e685c8e815489188eb8d468f31b90c",
              "IPY_MODEL_f008cecee2584fb5a2fde9ecccb863c8"
            ]
          }
        },
        "9111c9cfadf54bd29c9001b5b095c038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80e685c8e815489188eb8d468f31b90c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5abc383185d34a42af1742d21a588e6a",
            "_dom_classes": [],
            "description": "train epoch 3: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 798,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 798,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2cdbe8f119534f389666d8549eb1188e"
          }
        },
        "f008cecee2584fb5a2fde9ecccb863c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4529b69660554867a67b297c2ea6f74d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 798/798 [02:00&lt;00:00,  7.37it/s, loss=5.6]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc44d93044824ecd9dfadc1720594ee7"
          }
        },
        "5abc383185d34a42af1742d21a588e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2cdbe8f119534f389666d8549eb1188e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4529b69660554867a67b297c2ea6f74d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc44d93044824ecd9dfadc1720594ee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0ba96df2e2ae4d878f925380036d5cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_458e3f044b8f43dbb957954560d4c141",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2971a305446249d3a77f51e3ff795ed6",
              "IPY_MODEL_22d0cbee3d00442e91e507da828c4729"
            ]
          }
        },
        "458e3f044b8f43dbb957954560d4c141": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2971a305446249d3a77f51e3ff795ed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0bd550c80bf84e7f826abe342d42037f",
            "_dom_classes": [],
            "description": "validation: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 23,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 23,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5dcc52146c364d2fa99e6cc6293fdb3c"
          }
        },
        "22d0cbee3d00442e91e507da828c4729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_956c48979ec64fec84127b689c71ccb2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 23/23 [00:19&lt;00:00,  1.01s/it, valid_loss=6.23]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6ed08d660b54d878b9c2ccf96567e80"
          }
        },
        "0bd550c80bf84e7f826abe342d42037f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5dcc52146c364d2fa99e6cc6293fdb3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "956c48979ec64fec84127b689c71ccb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6ed08d660b54d878b9c2ccf96567e80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ab63514adb8489eb4cfd3536ee14192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_20b93187f221438a9e29ebf9c3111a4d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3819c78cd18f49faa73cb0bf8b5e3e71",
              "IPY_MODEL_5c0990dab20c425388a2994ce0c70af6"
            ]
          }
        },
        "20b93187f221438a9e29ebf9c3111a4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3819c78cd18f49faa73cb0bf8b5e3e71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7390e8efe9c545529e498278cf7db0fb",
            "_dom_classes": [],
            "description": "train epoch 4: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 798,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 798,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_755c30b10ae943b7bd2031b5fdcf9915"
          }
        },
        "5c0990dab20c425388a2994ce0c70af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aac0c860d70344f69bcac80378d9ee8f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 798/798 [02:00&lt;00:00,  7.34it/s, loss=5.39]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e50b32a845f4a07983b46468c1497cc"
          }
        },
        "7390e8efe9c545529e498278cf7db0fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "755c30b10ae943b7bd2031b5fdcf9915": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aac0c860d70344f69bcac80378d9ee8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e50b32a845f4a07983b46468c1497cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fce2a0578fa641d2b28ea6839fc264c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a6ae96b1b5974223be47204d38e5dfd6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7a5486d768594eb0bada30c0ced62cbb",
              "IPY_MODEL_b430a79e9bbd4c03bc89e6efbbf52c30"
            ]
          }
        },
        "a6ae96b1b5974223be47204d38e5dfd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a5486d768594eb0bada30c0ced62cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e8e24fe3acb945aa83cc279d1013c7e8",
            "_dom_classes": [],
            "description": "validation: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 23,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 23,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da9e1c5768634c6aa286c94dd8b45424"
          }
        },
        "b430a79e9bbd4c03bc89e6efbbf52c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c9613e4c4b4c44ab8455e97a64275a07",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 23/23 [00:20&lt;00:00,  1.06s/it, valid_loss=5.86]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac3dce7105bf4d08907d2d164b77d5bf"
          }
        },
        "e8e24fe3acb945aa83cc279d1013c7e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da9e1c5768634c6aa286c94dd8b45424": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c9613e4c4b4c44ab8455e97a64275a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac3dce7105bf4d08907d2d164b77d5bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a446ee961864bec988a1961c05abcdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a73578a49abe432d9273852a30934e0f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f0ea8e49f53e496d94d5dbccc9e04946",
              "IPY_MODEL_69a8d02e763946bfb85620caa11c0ec2"
            ]
          }
        },
        "a73578a49abe432d9273852a30934e0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0ea8e49f53e496d94d5dbccc9e04946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_515f36e9bb644504ae6cfccda11e5216",
            "_dom_classes": [],
            "description": "train epoch 5:   3%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 798,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 20,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_247a1bed65ea4ee0817dea7680e65a44"
          }
        },
        "69a8d02e763946bfb85620caa11c0ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_833b2c6456234127bbdf9d30d52e69f0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 20/798 [00:03&lt;01:58,  6.55it/s, loss=4.87]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f0399de85e946158ff77ec5df45fbe9"
          }
        },
        "515f36e9bb644504ae6cfccda11e5216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "247a1bed65ea4ee0817dea7680e65a44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "833b2c6456234127bbdf9d30d52e69f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f0399de85e946158ff77ec5df45fbe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Trsx0SVz4rZp"
      },
      "source": [
        "# **Homework 5 - Sequence-to-sequence**\n",
        "\n",
        "若有任何問題，歡迎來信至助教信箱 ntu-ml-2021spring-ta@googlegroups.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0NFMM9o4rZw"
      },
      "source": [
        "### (4/21 Updates)\n",
        "1. Link to reference [training curves](https://wandb.ai/george0828zhang/hw5.seq2seq.new).\n",
        "\n",
        "### (4/14 Updates) \n",
        "1. Link to tutorial [video](https://youtu.be/htG5WpZVQPU).\n",
        "2. Now defaults to load `\"avg_last_5_checkpoint.pt\"` to generate prediction.\n",
        "3. Expected run time on Colab with Tesla T4\n",
        "\n",
        "|Baseline|Details|Total Time|\n",
        "|-|:-:|:-:|\n",
        "|Simple|2m 15s $\\times$30 epochs|1hr 8m|\n",
        "|Medium|4m $\\times$30 epochs|2hr|\n",
        "|Strong|8m $\\times$30 epochs (backward)<br>+1hr (back-translation)<br>+15m $\\times$30 epochs (forward)|12hr 30m|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHXJCv5c4rZx"
      },
      "source": [
        "# Sequence-to-Sequence 介紹\n",
        "- 大多數常見的 seq2seq model 為 encoder-decoder model，主要由兩個部分組成，分別是 encoder 和 decoder，而這兩個部可以使用 recurrent neural network (RNN)或 transformer 來實作，主要是用來解決輸入和輸出的長度不一樣的情況\n",
        "- **Encoder** 是將一連串的輸入，如文字、影片、聲音訊號等，編碼為單個向量，這單個向量可以想像為是整個輸入的抽象表示，包含了整個輸入的資訊\n",
        "- **Decoder** 是將 encoder 輸出的單個向量逐步解碼，一次輸出一個結果，直到將最後目標輸出被產生出來為止，每次輸出會影響下一次的輸出，一般會在開頭加入 \"< BOS >\" 來表示開始解碼，會在結尾輸出 \"< EOS >\" 來表示輸出結束\n",
        "\n",
        "\n",
        "![seq2seq](https://i.imgur.com/0zeDyuI.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDvBBlRS4rZy"
      },
      "source": [
        "# 作業介紹\n",
        "- 英文翻譯中文\n",
        "  - 輸入： 一句英文 （e.g.\t\ttom is a student .） \n",
        "  - 輸出： 中文翻譯 （e.g. \t\t湯姆 是 個 學生 。）\n",
        "\n",
        "- TODO\n",
        "  - 訓練一個 RNN 模型達到 Seq2seq 翻譯\n",
        "  - 訓練一個 Transformer 大幅提升效能\n",
        "  - 實作 Back-translation 大幅提升效能"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtfdMeTD4rZz"
      },
      "source": [
        "# 下載和引入需要的函式庫"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zea7k4bc4rZz"
      },
      "source": [
        "!pip install 'torch>=1.6.0' editdistance matplotlib sacrebleu sacremoses sentencepiece tqdm wandb\n",
        "!pip install --upgrade jupyter ipywidgets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgisQ6394rZ0"
      },
      "source": [
        "!git clone https://github.com/pytorch/fairseq.git\n",
        "!cd fairseq && git checkout 9a1c497\n",
        "!pip install --upgrade ./fairseq/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJyvRjOx4rZ0"
      },
      "source": [
        "import sys\n",
        "import pdb\n",
        "import pprint\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "import tqdm.auto as tqdm\n",
        "from pathlib import Path\n",
        "from argparse import Namespace\n",
        "from fairseq import utils\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Bis2rBg4rZ1"
      },
      "source": [
        "# 設定種子"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_AXxIB04rZ1"
      },
      "source": [
        "seed = 42\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  \n",
        "np.random.seed(seed)  \n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27GEn2aa4rZ1"
      },
      "source": [
        "# 資料集介紹\n",
        "\n",
        "## 英轉繁雙語資料\n",
        "* [TED2020](#reimers-2020-multilingual-sentence-bert)\n",
        "    - 原始資料量: 398,066句    \n",
        "    - 處理後資料: 393,980句\n",
        "    \n",
        "\n",
        "## 測試資料\n",
        "- 資料量: 4,000句\n",
        "- **中文部分不公開，提供的檔案為假翻譯，全部都是句點。**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQYcX5oW4rZ2"
      },
      "source": [
        "# 資料下載"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmTZQoM54rZ2"
      },
      "source": [
        "### 安裝megatools (optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB_0UR8f4rZ2"
      },
      "source": [
        "!apt-get install megatools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMh_rMnw4rZ3"
      },
      "source": [
        "## 下載檔案並解壓縮"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRoz7eno4rZ3"
      },
      "source": [
        "data_dir = './DATA/rawdata'\n",
        "dataset_name = 'ted2020'\n",
        "urls = (\n",
        "    '\"https://onedrive.live.com/download?cid=3E549F3B24B238B4&resid=3E549F3B24B238B4%214989&authkey=AGgQ-DaR8eFSl1A\"', \n",
        "    '\"https://onedrive.live.com/download?cid=3E549F3B24B238B4&resid=3E549F3B24B238B4%214987&authkey=AA4qP_azsicwZZM\"',\n",
        "# # If the above links die, use the following instead. \n",
        "#     \"https://www.csie.ntu.edu.tw/~r09922057/ML2021-hw5/ted2020.tgz\",\n",
        "#     \"https://www.csie.ntu.edu.tw/~r09922057/ML2021-hw5/test.tgz\",\n",
        "# # If the above links die, use the following instead. \n",
        "#     \"https://mega.nz/#!vEcTCISJ!3Rw0eHTZWPpdHBTbQEqBDikDEdFPr7fI8WxaXK9yZ9U\",\n",
        "#     \"https://mega.nz/#!zNcnGIoJ!oPJX9AvVVs11jc0SaK6vxP_lFUNTkEcK2WbxJpvjU5Y\",\n",
        ")\n",
        "file_names = (\n",
        "    'ted2020.tgz', # train & dev\n",
        "    'test.tgz', # test\n",
        ")\n",
        "prefix = Path(data_dir).absolute() / dataset_name\n",
        "\n",
        "prefix.mkdir(parents=True, exist_ok=True)\n",
        "for u, f in zip(urls, file_names):\n",
        "    path = prefix/f\n",
        "    if not path.exists():\n",
        "        if 'mega' in u:\n",
        "            !megadl {u} --path {path}\n",
        "        else:\n",
        "            !wget {u} -O {path}\n",
        "    if path.suffix == \".tgz\":\n",
        "        !tar -xvf {path} -C {prefix}\n",
        "    elif path.suffix == \".zip\":\n",
        "        !unzip -o {path} -d {prefix}\n",
        "!mv {prefix/'raw.en'} {prefix/'train_dev.raw.en'}\n",
        "!mv {prefix/'raw.zh'} {prefix/'train_dev.raw.zh'}\n",
        "!mv {prefix/'test.en'} {prefix/'test.raw.en'}\n",
        "!mv {prefix/'test.zh'} {prefix/'test.raw.zh'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKHL0n-c4rZ4"
      },
      "source": [
        "## 設定語言"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIG87YjU4rZ4"
      },
      "source": [
        "src_lang = 'en'\n",
        "tgt_lang = 'zh'\n",
        "\n",
        "data_prefix = f'{prefix}/train_dev.raw'\n",
        "test_prefix = f'{prefix}/test.raw'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ENhAUD54rZ4",
        "outputId": "f22825df-7be0-4d1d-acd4-8e0289a23a1e"
      },
      "source": [
        "!head {data_prefix+'.'+src_lang} -n 5\n",
        "!head {data_prefix+'.'+tgt_lang} -n 5"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thank you so much, Chris.\n",
            "And it's truly a great honor to have the opportunity to come to this stage twice; I'm extremely grateful.\n",
            "I have been blown away by this conference, and I want to thank all of you for the many nice comments about what I had to say the other night.\n",
            "And I say that sincerely, partly because  I need that.\n",
            "Put yourselves in my position.\n",
            "非常謝謝你，克里斯。能有這個機會第二度踏上這個演講台\n",
            "真是一大榮幸。我非常感激。\n",
            "這個研討會給我留下了極為深刻的印象，我想感謝大家 對我之前演講的好評。\n",
            "我是由衷的想這麼說，有部份原因是因為 —— 我真的有需要!\n",
            "請你們設身處地為我想一想！\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usjV8a5r4rZ4"
      },
      "source": [
        "## 檔案前處理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibfH7_114rZ5"
      },
      "source": [
        "import re\n",
        "\n",
        "def strQ2B(ustring):\n",
        "    \"\"\"把字串全形轉半形\"\"\"\n",
        "    # 參考來源:https://ithelp.ithome.com.tw/articles/10233122\n",
        "    ss = []\n",
        "    for s in ustring:\n",
        "        rstring = \"\"\n",
        "        for uchar in s:\n",
        "            inside_code = ord(uchar)\n",
        "            if inside_code == 12288:  # 全形空格直接轉換\n",
        "                inside_code = 32\n",
        "            elif (inside_code >= 65281 and inside_code <= 65374):  # 全形字元（除空格）根據關係轉化\n",
        "                inside_code -= 65248\n",
        "            rstring += chr(inside_code)\n",
        "        ss.append(rstring)\n",
        "    return ''.join(ss)\n",
        "                \n",
        "def clean_s(s, lang):\n",
        "    if lang == 'en':\n",
        "        s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])\n",
        "        s = s.replace('-', '') # remove '-'\n",
        "        s = re.sub('([.,;!?()\\\"])', r' \\1 ', s) # keep punctuation\n",
        "    elif lang == 'zh':\n",
        "        s = strQ2B(s) # Q2B\n",
        "        s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])\n",
        "        s = s.replace(' ', '')\n",
        "        s = s.replace('—', '')\n",
        "        s = s.replace('“', '\"')\n",
        "        s = s.replace('”', '\"')\n",
        "        s = s.replace('_', '')\n",
        "        s = re.sub('([。,;!?()\\\"~「」])', r' \\1 ', s) # keep punctuation\n",
        "    s = ' '.join(s.strip().split())\n",
        "    return s\n",
        "\n",
        "def len_s(s, lang):\n",
        "    if lang == 'zh':\n",
        "        return len(s)\n",
        "    return len(s.split())\n",
        "\n",
        "def clean_corpus(prefix, l1, l2, ratio=9, max_len=1000, min_len=1):\n",
        "    if Path(f'{prefix}.clean.{l1}').exists() and Path(f'{prefix}.clean.{l2}').exists():\n",
        "        print(f'{prefix}.clean.{l1} & {l2} exists. skipping clean.')\n",
        "        return\n",
        "    with open(f'{prefix}.{l1}', 'r') as l1_in_f:\n",
        "        with open(f'{prefix}.{l2}', 'r') as l2_in_f:\n",
        "            with open(f'{prefix}.clean.{l1}', 'w') as l1_out_f:\n",
        "                with open(f'{prefix}.clean.{l2}', 'w') as l2_out_f:\n",
        "                    for s1 in l1_in_f:\n",
        "                        s1 = s1.strip()\n",
        "                        s2 = l2_in_f.readline().strip()\n",
        "                        s1 = clean_s(s1, l1)\n",
        "                        s2 = clean_s(s2, l2)\n",
        "                        s1_len = len_s(s1, l1)\n",
        "                        s2_len = len_s(s2, l2)\n",
        "                        if min_len > 0: # remove short sentence\n",
        "                            if s1_len < min_len or s2_len < min_len:\n",
        "                                continue\n",
        "                        if max_len > 0: # remove long sentence\n",
        "                            if s1_len > max_len or s2_len > max_len:\n",
        "                                continue\n",
        "                        if ratio > 0: # remove by ratio of length\n",
        "                            if s1_len/s2_len > ratio or s2_len/s1_len > ratio:\n",
        "                                continue\n",
        "                        print(s1, file=l1_out_f)\n",
        "                        print(s2, file=l2_out_f)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSHfp_144rZ6"
      },
      "source": [
        "clean_corpus(data_prefix, src_lang, tgt_lang)\n",
        "clean_corpus(test_prefix, src_lang, tgt_lang, ratio=-1, min_len=-1, max_len=-1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG38NzIo4rZ6",
        "outputId": "d18f71f5-e74d-4c07-fd41-bd7383ab5e52"
      },
      "source": [
        "!head {data_prefix+'.clean.'+src_lang} -n 5\n",
        "!head {data_prefix+'.clean.'+tgt_lang} -n 5"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thank you so much , Chris .\n",
            "And it's truly a great honor to have the opportunity to come to this stage twice ; I'm extremely grateful .\n",
            "I have been blown away by this conference , and I want to thank all of you for the many nice comments about what I had to say the other night .\n",
            "And I say that sincerely , partly because I need that .\n",
            "Put yourselves in my position .\n",
            "非常謝謝你 , 克里斯 。 能有這個機會第二度踏上這個演講台\n",
            "真是一大榮幸 。 我非常感激 。\n",
            "這個研討會給我留下了極為深刻的印象 , 我想感謝大家對我之前演講的好評 。\n",
            "我是由衷的想這麼說 , 有部份原因是因為我真的有需要 !\n",
            "請你們設身處地為我想一想 !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtU9E3WN4rZ7"
      },
      "source": [
        "## 切出 train/valid set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGq99ZKe4rZ7"
      },
      "source": [
        "valid_ratio = 0.01 # 3000~4000句就夠了\n",
        "train_ratio = 1 - valid_ratio"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5ZIpzNC4rZ7"
      },
      "source": [
        "if (prefix/f'train.clean.{src_lang}').exists() \\\n",
        "and (prefix/f'train.clean.{tgt_lang}').exists() \\\n",
        "and (prefix/f'valid.clean.{src_lang}').exists() \\\n",
        "and (prefix/f'valid.clean.{tgt_lang}').exists():\n",
        "    print(f'train/valid splits exists. skipping split.')\n",
        "else:\n",
        "    line_num = sum(1 for line in open(f'{data_prefix}.clean.{src_lang}'))\n",
        "    labels = list(range(line_num))\n",
        "    random.shuffle(labels)\n",
        "    for lang in [src_lang, tgt_lang]:\n",
        "        train_f = open(os.path.join(data_dir, dataset_name, f'train.clean.{lang}'), 'w')\n",
        "        valid_f = open(os.path.join(data_dir, dataset_name, f'valid.clean.{lang}'), 'w')\n",
        "        count = 0\n",
        "        for line in open(f'{data_prefix}.clean.{lang}', 'r'):\n",
        "            if labels[count]/line_num < train_ratio:\n",
        "                train_f.write(line)\n",
        "            else:\n",
        "                valid_f.write(line)\n",
        "            count += 1\n",
        "        train_f.close()\n",
        "        valid_f.close()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O-wFRn34rZ8"
      },
      "source": [
        "## Subword Units \n",
        "翻譯存在的一大問題是未登錄詞(out of vocabulary)，可以使用 subword units 作為斷詞單位來解決。\n",
        "- 使用 [sentencepiece](#kudo-richardson-2018-sentencepiece) 套件\n",
        "- 用 unigram 或 byte-pair encoding (BPE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l7_1XbT4rZ8"
      },
      "source": [
        "import sentencepiece as spm\n",
        "vocab_size = 8000\n",
        "if (prefix/f'spm{vocab_size}.model').exists():\n",
        "    print(f'{prefix}/spm{vocab_size}.model exists. skipping spm_train.')\n",
        "else:\n",
        "    spm.SentencePieceTrainer.train(\n",
        "        input=','.join([f'{prefix}/train.clean.{src_lang}',\n",
        "                        f'{prefix}/valid.clean.{src_lang}',\n",
        "                        f'{prefix}/train.clean.{tgt_lang}',\n",
        "                        f'{prefix}/valid.clean.{tgt_lang}']),\n",
        "        model_prefix=prefix/f'spm{vocab_size}',\n",
        "        vocab_size=vocab_size,\n",
        "        character_coverage=1,\n",
        "        model_type='unigram', # 'bpe' 也可\n",
        "        input_sentence_size=1e6,\n",
        "        shuffle_input_sentence=True,\n",
        "        normalization_rule_name='nmt_nfkc_cf',\n",
        "    )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "686zLfa94rZ8"
      },
      "source": [
        "spm_model = spm.SentencePieceProcessor(model_file=str(prefix/f'spm{vocab_size}.model'))\n",
        "in_tag = {\n",
        "    'train': 'train.clean',\n",
        "    'valid': 'valid.clean',\n",
        "    'test': 'test.raw.clean',\n",
        "}\n",
        "for split in ['train', 'valid', 'test']:\n",
        "    for lang in [src_lang, tgt_lang]:\n",
        "        out_path = prefix/f'{split}.{lang}'\n",
        "        if out_path.exists():\n",
        "            print(f\"{out_path} exists. skipping spm_encode.\")\n",
        "        else:\n",
        "            with open(prefix/f'{split}.{lang}', 'w') as out_f:\n",
        "                with open(prefix/f'{in_tag[split]}.{lang}', 'r') as in_f:\n",
        "                    for line in in_f:\n",
        "                        line = line.strip()\n",
        "                        tok = spm_model.encode(line, out_type=str)\n",
        "                        print(' '.join(tok), file=out_f)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjCcvDdc4rZ9",
        "outputId": "9425bd04-5d5d-4a8d-d8f8-41e824341f22"
      },
      "source": [
        "!head {data_dir+'/'+dataset_name+'/train.'+src_lang} -n 5\n",
        "!head {data_dir+'/'+dataset_name+'/train.'+tgt_lang} -n 5"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "▁thank ▁you ▁so ▁much ▁, ▁chris ▁.\n",
            "▁and ▁it ' s ▁tr u ly ▁a ▁great ▁ho n or ▁to ▁have ▁the ▁ op port un ity ▁to ▁come ▁to ▁this ▁st age ▁ t wi ce ▁ ; ▁i ' m ▁ex t re me ly ▁g rate ful ▁.\n",
            "▁i ▁have ▁been ▁ bl own ▁away ▁by ▁this ▁con fer ence ▁, ▁and ▁i ▁want ▁to ▁thank ▁all ▁of ▁you ▁for ▁the ▁many ▁ ni ce ▁ com ment s ▁about ▁what ▁i ▁had ▁to ▁say ▁the ▁other ▁night ▁.\n",
            "▁and ▁i ▁say ▁that ▁since re ly ▁, ▁part ly ▁because ▁i ▁need ▁that ▁.\n",
            "▁put ▁your s el ve s ▁in ▁my ▁po s ition ▁.\n",
            "▁ 非常 謝 謝 你 ▁, ▁ 克 里 斯 ▁。 ▁ 能 有 這個 機會 第二 度 踏 上 這個 演講 台\n",
            "▁ 真 是 一 大 榮 幸 ▁。 ▁我 非常 感 激 ▁。\n",
            "▁這個 研 討 會 給我 留 下 了 極 為 深 刻 的 印 象 ▁, ▁我想 感 謝 大家 對 我 之前 演講 的 好 評 ▁。\n",
            "▁我 是由 衷 的 想 這麼 說 ▁, ▁有 部份 原因 是因為 我 真的 有 需要 ▁ !\n",
            "▁ 請 你們 設 身 處 地 為 我想 一 想 ▁ !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpoE1yyT4rZ9"
      },
      "source": [
        "## 用 fairseq 將資料轉為 binary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeAip8QM4rZ9",
        "outputId": "9acbd16c-f8fa-476c-d672-b4708e0b469a"
      },
      "source": [
        "binpath = Path('./DATA/data-bin', dataset_name)\n",
        "if binpath.exists():\n",
        "    print(binpath, \"exists, will not overwrite!\")\n",
        "else:\n",
        "    !python -m fairseq_cli.preprocess \\\n",
        "        --source-lang {src_lang}\\\n",
        "        --target-lang {tgt_lang}\\\n",
        "        --trainpref {prefix/'train'}\\\n",
        "        --validpref {prefix/'valid'}\\\n",
        "        --testpref {prefix/'test'}\\\n",
        "        --destdir {binpath}\\\n",
        "        --joined-dictionary\\\n",
        "        --workers 2"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-15 07:35:16 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='DATA/data-bin/ted2020', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='en', srcdict=None, suppress_crashes=False, target_lang='zh', task='translation', tensorboard_logdir=None, testpref='/content/DATA/rawdata/ted2020/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/content/DATA/rawdata/ted2020/train', user_dir=None, validpref='/content/DATA/rawdata/ted2020/valid', wandb_project=None, workers=2)\n",
            "2021-05-15 07:36:22 | INFO | fairseq_cli.preprocess | [en] Dictionary: 7992 types\n",
            "2021-05-15 07:37:12 | INFO | fairseq_cli.preprocess | [en] /content/DATA/rawdata/ted2020/train.en: 390041 sents, 12348449 tokens, 0.0% replaced by <unk>\n",
            "2021-05-15 07:37:12 | INFO | fairseq_cli.preprocess | [en] Dictionary: 7992 types\n",
            "2021-05-15 07:37:13 | INFO | fairseq_cli.preprocess | [en] /content/DATA/rawdata/ted2020/valid.en: 3939 sents, 124286 tokens, 0.000805% replaced by <unk>\n",
            "2021-05-15 07:37:13 | INFO | fairseq_cli.preprocess | [en] Dictionary: 7992 types\n",
            "2021-05-15 07:37:13 | INFO | fairseq_cli.preprocess | [en] /content/DATA/rawdata/ted2020/test.en: 4000 sents, 124155 tokens, 0.0% replaced by <unk>\n",
            "2021-05-15 07:37:13 | INFO | fairseq_cli.preprocess | [zh] Dictionary: 7992 types\n",
            "2021-05-15 07:37:57 | INFO | fairseq_cli.preprocess | [zh] /content/DATA/rawdata/ted2020/train.zh: 390041 sents, 9596936 tokens, 0.0% replaced by <unk>\n",
            "2021-05-15 07:37:57 | INFO | fairseq_cli.preprocess | [zh] Dictionary: 7992 types\n",
            "2021-05-15 07:37:57 | INFO | fairseq_cli.preprocess | [zh] /content/DATA/rawdata/ted2020/valid.zh: 3939 sents, 96292 tokens, 0.0104% replaced by <unk>\n",
            "2021-05-15 07:37:57 | INFO | fairseq_cli.preprocess | [zh] Dictionary: 7992 types\n",
            "2021-05-15 07:37:57 | INFO | fairseq_cli.preprocess | [zh] /content/DATA/rawdata/ted2020/test.zh: 4000 sents, 8000 tokens, 0.0% replaced by <unk>\n",
            "2021-05-15 07:37:57 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to DATA/data-bin/ted2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAMYH9544rZ-"
      },
      "source": [
        "# 實驗的參數設定表"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS_kdEiU4rZ-"
      },
      "source": [
        "config = Namespace(\n",
        "    datadir = \"./DATA/data-bin/ted2020\",\n",
        "    savedir = \"./checkpoints/rnn\",\n",
        "    source_lang = \"en\",\n",
        "    target_lang = \"zh\",\n",
        "    \n",
        "    # cpu threads when fetching & processing data.\n",
        "    num_workers=2,  \n",
        "    # batch size in terms of tokens. gradient accumulation increases the effective batchsize.\n",
        "    max_tokens=8192,\n",
        "    accum_steps=2,\n",
        "    \n",
        "    # the lr s calculated from Noam lr scheduler. you can tune the maximum lr by this factor.\n",
        "    lr_factor=2.,\n",
        "    lr_warmup=4000,\n",
        "    \n",
        "    # clipping gradient norm helps alleviate gradient exploding\n",
        "    clip_norm=1.0,\n",
        "    \n",
        "    # maximum epochs for training\n",
        "    max_epoch=30,\n",
        "    start_epoch=1,\n",
        "    \n",
        "    # beam size for beam search\n",
        "    beam=5, \n",
        "    # generate sequences of maximum length ax + b, where x is the source length\n",
        "    max_len_a=1.2, \n",
        "    max_len_b=10,\n",
        "    # when decoding, post process sentence by removing sentencepiece symbols.\n",
        "    post_process = \"sentencepiece\",\n",
        "    \n",
        "    # checkpoints\n",
        "    keep_last_epochs=5,\n",
        "    resume=None, # if resume from checkpoint name (under config.savedir)\n",
        "    \n",
        "    # logging\n",
        "    use_wandb=False,\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxGUh4DX4rZ-"
      },
      "source": [
        "# Logging\n",
        "- logging 套件紀錄一般訊息\n",
        "- wandb 紀錄續練過程 loss, bleu, model weight 等等"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "XHax9Mzf4rZ_"
      },
      "source": [
        "logging.basicConfig(\n",
        "    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n",
        "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        "    level=\"INFO\", # \"DEBUG\" \"WARNING\" \"ERROR\"\n",
        "    stream=sys.stdout,\n",
        ")\n",
        "proj = \"hw5.seq2seq\"\n",
        "logger = logging.getLogger(proj)\n",
        "if config.use_wandb:\n",
        "    import wandb\n",
        "    wandb.init(project=proj, name=Path(config.savedir).stem, config=config)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLJ-ucof4rZ_"
      },
      "source": [
        "# CUDA環境"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdMJwe684rZ_",
        "outputId": "f4bd75b9-fffe-4ec2-fc33-9cad29145a89"
      },
      "source": [
        "cuda_env = utils.CudaEnvironment()\n",
        "utils.CudaEnvironment.pretty_print_cuda_env_list([cuda_env])\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-15 07:38:14 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-05-15 07:38:14 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.756 GB ; name = Tesla T4                                \n",
            "2021-05-15 07:38:14 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rapUqzq84rZ_"
      },
      "source": [
        "# 讀取資料集"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhpGFkbP4raA"
      },
      "source": [
        "## 借用 fairseq 的 TranslationTask\n",
        "* 用來讀進上面 binarized 的檔案\n",
        "* 有現成的 data iterator (dataloader)\n",
        "* 字典 task.source_dictionary 和 task.target_dictionary 也很好用 \n",
        "* 有實做 beam search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1cZ9PIP4raA",
        "outputId": "2bcb2df1-539e-4962-a710-dca316df87b1"
      },
      "source": [
        "from fairseq.tasks.translation import TranslationConfig, TranslationTask\n",
        "\n",
        "## setup task\n",
        "task_cfg = TranslationConfig(\n",
        "    data=config.datadir,\n",
        "    source_lang=config.source_lang,\n",
        "    target_lang=config.target_lang,\n",
        "    train_subset=\"train\",\n",
        "    required_seq_len_multiple=8,\n",
        "    dataset_impl=\"mmap\",\n",
        "    upsample_primary=1,\n",
        ")\n",
        "task = TranslationTask.setup_task(task_cfg)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-15 07:39:28 | INFO | fairseq.tasks.translation | [en] dictionary: 7992 types\n",
            "2021-05-15 07:39:28 | INFO | fairseq.tasks.translation | [zh] dictionary: 7992 types\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCnCsQXG4raA",
        "outputId": "131e2f0a-c0c7-495f-b294-485b13d4a008"
      },
      "source": [
        "logger.info(\"loading data for epoch 1\")\n",
        "task.load_dataset(split=\"train\", epoch=1, combine=True) # combine if you have back-translation data.\n",
        "task.load_dataset(split=\"valid\", epoch=1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-15 07:39:34 | INFO | hw5.seq2seq | loading data for epoch 1\n",
            "2021-05-15 07:39:34 | INFO | fairseq.data.data_utils | loaded 390,041 examples from: ./DATA/data-bin/ted2020/train.en-zh.en\n",
            "2021-05-15 07:39:34 | INFO | fairseq.data.data_utils | loaded 390,041 examples from: ./DATA/data-bin/ted2020/train.en-zh.zh\n",
            "2021-05-15 07:39:34 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020 train en-zh 390041 examples\n",
            "2021-05-15 07:39:34 | INFO | fairseq.data.data_utils | loaded 3,939 examples from: ./DATA/data-bin/ted2020/valid.en-zh.en\n",
            "2021-05-15 07:39:34 | INFO | fairseq.data.data_utils | loaded 3,939 examples from: ./DATA/data-bin/ted2020/valid.en-zh.zh\n",
            "2021-05-15 07:39:34 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020 valid en-zh 3939 examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mal5JPSC4raB",
        "outputId": "5bb25b29-b45d-4aa4-affd-3838afb41f3b"
      },
      "source": [
        "sample = task.dataset(\"valid\")[1]\n",
        "pprint.pprint(sample)\n",
        "pprint.pprint(\n",
        "    \"Source: \" + \\\n",
        "    task.source_dictionary.string(\n",
        "        sample['source'],\n",
        "        config.post_process,\n",
        "    )\n",
        ")\n",
        "pprint.pprint(\n",
        "    \"Target: \" + \\\n",
        "    task.target_dictionary.string(\n",
        "        sample['target'],\n",
        "        config.post_process,\n",
        "    )\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'id': 1,\n",
            " 'source': tensor([  17,    6,  335,  520,  331,   59,  884,    5,   22,  842,   22,    6,\n",
            "          13,    5,  567,  166, 2319,   56, 2079,    6,    4,   17,  511,  308,\n",
            "         900, 1394,   11,    5,  837, 1381,  825,   11,  316,  205,  760,   28,\n",
            "        1015,   73,  206,  117,    7,    2]),\n",
            " 'target': tensor([   5, 4047, 1938,  678,  299, 1081,  424,    9, 3437, 4265,  923, 1638,\n",
            "        2895,    9, 1373, 1049, 2981, 2271,  232,  245, 1626,  651, 3078, 1108,\n",
            "           9,  687, 2508, 1520,    2])}\n",
            "('Source: institutional design requires a keen focus on issues , innovative '\n",
            " 'thinking and flexible and wellfunded implementation .')\n",
            "'Target: 憲政設計需要對於問題的敏銳專注創新的思考以及具有彈性與資金充足的實施方法'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XGGp5Se4raB"
      },
      "source": [
        "## Dataset Iterator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obH4fcnw4raB"
      },
      "source": [
        "* 將每個 batch 控制在 N 個 token 讓 GPU 記憶體更有效被利用\n",
        "* 讓 training set 每個 epoch 有不同 shuffling\n",
        "* 濾掉長度太長的句子\n",
        "* 將每個 batch 內的句子 pad 成一樣長，好讓 GPU 平行運算\n",
        "* 加上 eos 並 shift 一格\n",
        "    - teacher forcing: 為了訓練模型根據prefix生成下個字，decoder的輸入會是輸出目標序列往右shift一格。\n",
        "    - 一般是會在輸入開頭加個bos token (如下圖)\n",
        "![seq2seq](https://i.imgur.com/0zeDyuI.png)\n",
        "    - fairseq 則是直接把 eos 挪到 beginning，訓練起來效果其實差不多。例如: \n",
        "    ```\n",
        "    # 輸出目標 (target) 和 Decoder輸入 (prev_output_tokens): \n",
        "                   eos = 2\n",
        "                target = 419,  711,  238,  888,  792,   60,  968,    8,    2\n",
        "    prev_output_tokens = 2,  419,  711,  238,  888,  792,   60,  968,    8\n",
        "    ```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9HmhO0R4raB",
        "outputId": "9202c441-97ba-4b92-cd0b-ea0186e37c4b"
      },
      "source": [
        "def load_data_iterator(task, split, epoch=1, max_tokens=4000, num_workers=1, cached=True):\n",
        "    batch_iterator = task.get_batch_iterator(\n",
        "        dataset=task.dataset(split),\n",
        "        max_tokens=max_tokens,\n",
        "        max_sentences=None,\n",
        "        max_positions=utils.resolve_max_positions(\n",
        "            task.max_positions(),\n",
        "            max_tokens,\n",
        "        ),\n",
        "        ignore_invalid_inputs=True,\n",
        "        seed=seed,\n",
        "        num_workers=num_workers,\n",
        "        epoch=epoch,\n",
        "        disable_iterator_cache=not cached,\n",
        "        # Set this to False to speed up. However, if set to False, changing max_tokens beyond \n",
        "        # first call of this method has no effect. \n",
        "    )\n",
        "    return batch_iterator\n",
        "\n",
        "demo_epoch_obj = load_data_iterator(task, \"valid\", epoch=1, max_tokens=20, num_workers=1, cached=False)\n",
        "demo_iter = demo_epoch_obj.next_epoch_itr(shuffle=True)\n",
        "sample = next(demo_iter)\n",
        "sample"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-15 07:54:57 | WARNING | fairseq.tasks.fairseq_task | 2,608 samples have invalid sizes and will be skipped, max_positions=(20, 20), first few sample ids=[959, 2623, 760, 3189, 2847, 3338, 2844, 1251, 3731, 1764]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': tensor([ 981, 2131]),\n",
              " 'net_input': {'prev_output_tokens': tensor([[   2, 1103,  564,    1,    1,    1,    1,    1],\n",
              "          [   2, 1103,   10,    1,    1,    1,    1,    1]]),\n",
              "  'src_lengths': tensor([7, 7]),\n",
              "  'src_tokens': tensor([[  1, 660,  25,   5, 183, 402,   7,   2],\n",
              "          [  1, 660,  25,   5, 183, 402,   7,   2]])},\n",
              " 'nsentences': 2,\n",
              " 'ntokens': 6,\n",
              " 'target': tensor([[1103,  564,    2,    1,    1,    1,    1,    1],\n",
              "         [1103,   10,    2,    1,    1,    1,    1,    1]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0_RqkVi4raC"
      },
      "source": [
        "* 每個 batch 是一個字典，key 是字串，value 是 Tensor，內容說明如下\n",
        "```python\n",
        "batch = {\n",
        "    \"id\": id, # 每個 example 的 id\n",
        "    \"nsentences\": len(samples), # batch size 句子數\n",
        "    \"ntokens\": ntokens, # batch size 字數\n",
        "    \"net_input\": {\n",
        "        \"src_tokens\": src_tokens, # 來源語言的序列\n",
        "        \"src_lengths\": src_lengths, # 每句話沒有 pad 過的長度\n",
        "        \"prev_output_tokens\": prev_output_tokens, # 上面提到右 shift 一格後的目標序列\n",
        "    },\n",
        "    \"target\": target, # 目標序列\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxGjnnfD4raC"
      },
      "source": [
        "# 定義模型架構\n",
        "* 我們一樣繼承 fairseq 的 encoder, decoder 和 model, 這樣測試階段才能直接用他寫好的 beam search 函式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyUoCx2b4raC"
      },
      "source": [
        "from fairseq.models import (\n",
        "    FairseqEncoder, \n",
        "    FairseqIncrementalDecoder,\n",
        "    FairseqEncoderDecoderModel\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZUsD6vW4raC"
      },
      "source": [
        "## Encoder 編碼器"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QVMiqxy4raD"
      },
      "source": [
        "- seq2seq 模型的編碼器為 RNN 或 Transformer Encoder，以下說明以 RNN 為例，Transformer 略有不同。對於每個輸入，Encoder 會輸出一個向量和一個隱藏狀態(hidden state)，並將隱藏狀態用於下一個輸入。換句話說，Encoder 會逐步讀取輸入序列，並在每個 timestep 輸出單個向量，以及在最後 timestep 輸出最終隱藏狀態(content vector)\n",
        "- 參數:\n",
        "  - *args*\n",
        "      - encoder_embed_dim 是 embedding 的維度，主要將 one-hot vector 的單詞向量壓縮到指定的維度，主要是為了降維和濃縮資訊的功用\n",
        "      - encoder_ffn_embed_dim 是 RNN 輸出和隱藏狀態的維度(hidden dimension)\n",
        "      - encoder_layers 是 RNN 要疊多少層\n",
        "      - dropout 是決定有多少的機率會將某個節點變為 0，主要是為了防止 overfitting ，一般來說是在訓練時使用，測試時則不使用\n",
        "  - *dictionary*: fairseq 幫我們做好的 dictionary. 在此用來得到 padding index，好用來得到 encoder padding mask. \n",
        "  - *embed_tokens*: 事先做好的詞嵌入 (nn.Embedding)\n",
        "\n",
        "- 輸入: \n",
        "    - *src_tokens*: 英文的整數序列 e.g. 1, 28, 29, 205, 2 \n",
        "- 輸出: \n",
        "    - *outputs*: 最上層 RNN 每個 timestep 的輸出，後續可以用 Attention 再進行處理\n",
        "    - *final_hiddens*: 每層最終 timestep 的隱藏狀態，將傳遞到 Decoder 進行解碼\n",
        "    - *encoder_padding_mask*: 告訴我們哪些是位置的資訊不重要。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPywVkD44raD"
      },
      "source": [
        "class RNNEncoder(FairseqEncoder):\n",
        "    def __init__(self, args, dictionary, embed_tokens):\n",
        "        super().__init__(dictionary)\n",
        "        self.embed_tokens = embed_tokens\n",
        "        \n",
        "        self.embed_dim = args.encoder_embed_dim\n",
        "        self.hidden_dim = args.encoder_ffn_embed_dim\n",
        "        self.num_layers = args.encoder_layers\n",
        "        \n",
        "        self.dropout_in_module = nn.Dropout(args.dropout)\n",
        "        self.rnn = nn.GRU(\n",
        "            self.embed_dim, \n",
        "            self.hidden_dim, \n",
        "            self.num_layers, \n",
        "            dropout=args.dropout, \n",
        "            batch_first=False, \n",
        "            bidirectional=True\n",
        "        )\n",
        "        self.dropout_out_module = nn.Dropout(args.dropout)\n",
        "        \n",
        "        self.padding_idx = dictionary.pad()\n",
        "        \n",
        "    def combine_bidir(self, outs, bsz: int):\n",
        "        out = outs.view(self.num_layers, 2, bsz, -1).transpose(1, 2).contiguous()\n",
        "        return out.view(self.num_layers, bsz, -1)\n",
        "\n",
        "    def forward(self, src_tokens, **unused):\n",
        "        bsz, seqlen = src_tokens.size()\n",
        "        \n",
        "        # get embeddings\n",
        "        x = self.embed_tokens(src_tokens)\n",
        "        x = self.dropout_in_module(x)\n",
        "\n",
        "        # B x T x C -> T x B x C\n",
        "        x = x.transpose(0, 1)\n",
        "        \n",
        "        # 過雙向RNN\n",
        "        h0 = x.new_zeros(2 * self.num_layers, bsz, self.hidden_dim)\n",
        "        x, final_hiddens = self.rnn(x, h0)\n",
        "        outputs = self.dropout_out_module(x)\n",
        "        # outputs = [sequence len, batch size, hid dim * directions] 是最上層RNN的輸出\n",
        "        # hidden =  [num_layers * directions, batch size  , hid dim]\n",
        "        \n",
        "        # 因為 Encoder 是雙向的RNN，所以需要將同一層兩個方向的 hidden state 接在一起\n",
        "        final_hiddens = self.combine_bidir(final_hiddens, bsz)\n",
        "        # hidden =  [num_layers x batch x num_directions*hidden]\n",
        "        \n",
        "        encoder_padding_mask = src_tokens.eq(self.padding_idx).t()\n",
        "        return tuple(\n",
        "            (\n",
        "                outputs,  # seq_len x batch x hidden\n",
        "                final_hiddens,  # num_layers x batch x num_directions*hidden\n",
        "                encoder_padding_mask,  # seq_len x batch\n",
        "            )\n",
        "        )\n",
        "    \n",
        "    def reorder_encoder_out(self, encoder_out, new_order):\n",
        "        # 這個beam search時會用到，意義並不是很重要\n",
        "        return tuple(\n",
        "            (\n",
        "                encoder_out[0].index_select(1, new_order),\n",
        "                encoder_out[1].index_select(1, new_order),\n",
        "                encoder_out[2].index_select(1, new_order),\n",
        "            )\n",
        "        )"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZBUcfOx4raD"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBkcdhTc4raE"
      },
      "source": [
        "- 當輸入過長，或是單獨靠 “content vector” 無法取得整個輸入的意思時，用 Attention Mechanism 來提供 Decoder 更多的資訊\n",
        "- 根據現在 **Decoder embeddings** ，去計算在 **Encoder outputs** 中，那些與其有較高的關係，根據關係的數值來把 Encoder outputs 平均起來作為 **Decoder** RNN 的輸入 \n",
        "- 常見 Attention 的實作是用 Neural Network / Dot Product 來算 **query** (decoder embeddings) 和 **key** (Encoder outputs) 之間的關係，再對所有算出來的數值做 **softmax** 得到分佈，最後根據這個分佈對 **values** (Encoder outputs) 做 **weight sum**\n",
        "\n",
        "- 參數:\n",
        "  - *input_embed_dim*: key 的維度，應是 decoder 要做 attend 時的向量的維度\n",
        "  - *source_embed_dim*: query 的維度，應是要被 attend 的向量(encoder outputs)的維度\n",
        "  - *output_embed_dim*: value 的維度，應是做完 attention 後，下一層預期的向量維度\n",
        "\n",
        "- 輸入: \n",
        "    - *inputs*: 就是 key，要 attend 別人的向量\n",
        "    - *encoder_outputs*: 是 query/value，被 attend 的向量\n",
        "    - *encoder_padding_mask*: 告訴我們哪些是位置的資訊不重要。\n",
        "- 輸出: \n",
        "    - *output*: 做完 attention 後的 context vector\n",
        "    - *attention score*: attention 的分布\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MumGJR0v4raE"
      },
      "source": [
        "class AttentionLayer(nn.Module):\n",
        "    def __init__(self, input_embed_dim, source_embed_dim, output_embed_dim, bias=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_proj = nn.Linear(input_embed_dim, source_embed_dim, bias=bias)\n",
        "        self.output_proj = nn.Linear(\n",
        "            input_embed_dim + source_embed_dim, output_embed_dim, bias=bias\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs, encoder_outputs, encoder_padding_mask):\n",
        "        # inputs: T, B, dim\n",
        "        # encoder_outputs: S x B x dim\n",
        "        # padding mask:  S x B\n",
        "        \n",
        "        # convert all to batch first\n",
        "        inputs = inputs.transpose(1,0) # B, T, dim\n",
        "        encoder_outputs = encoder_outputs.transpose(1,0) # B, S, dim\n",
        "        encoder_padding_mask = encoder_padding_mask.transpose(1,0) # B, S\n",
        "        \n",
        "        # 投影到encoder_outputs的維度\n",
        "        x = self.input_proj(inputs)\n",
        "\n",
        "        # 計算attention\n",
        "        # (B, T, dim) x (B, dim, S) = (B, T, S)\n",
        "        attn_scores = torch.bmm(x, encoder_outputs.transpose(1,2))\n",
        "\n",
        "        # 擋住padding位置的attention\n",
        "        if encoder_padding_mask is not None:\n",
        "            # 利用broadcast  B, S -> (B, 1, S)\n",
        "            encoder_padding_mask = encoder_padding_mask.unsqueeze(1)\n",
        "            attn_scores = (\n",
        "                attn_scores.float()\n",
        "                .masked_fill_(encoder_padding_mask, float(\"-inf\"))\n",
        "                .type_as(attn_scores)\n",
        "            )  # FP16 support: cast to float and back\n",
        "\n",
        "        # 在source對應維度softmax\n",
        "        attn_scores = F.softmax(attn_scores, dim=-1)\n",
        "\n",
        "        # 形狀 (B, T, S) x (B, S, dim) = (B, T, dim) 加權平均\n",
        "        x = torch.bmm(attn_scores, encoder_outputs)\n",
        "\n",
        "        # (B, T, dim)\n",
        "        x = torch.cat((x, inputs), dim=-1)\n",
        "        x = torch.tanh(self.output_proj(x)) # concat + linear + tanh\n",
        "        \n",
        "        # 回復形狀 (B, T, dim) -> (T, B, dim)\n",
        "        return x.transpose(1,0), attn_scores"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vROFRnkw4raE"
      },
      "source": [
        "## Decoder 解碼器"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiaKHoST4raE"
      },
      "source": [
        "* 解碼器的 hidden states 會用編碼器最終隱藏狀態來初始化(content vector)\n",
        "* 解碼器同時也根據目前 timestep 的輸入(也就是前幾個 timestep 的 output)，改變 hidden states，並輸出結果 \n",
        "* 如果加入 attention 可以使表現更好\n",
        "* 我們把 seq2seq 步驟寫在解碼器裡，好讓等等 Seq2Seq 這個型別可以通用 RNN 和 Transformer，而不用再改寫\n",
        "- 參數:\n",
        "  - *args*\n",
        "      - decoder_embed_dim 是解碼器 embedding 的維度，類同 encoder_embed_dim，\n",
        "      - decoder_ffn_embed_dim 是解碼器 RNN 的隱藏維度，類同 encoder_ffn_embed_dim\n",
        "      - decoder_layers 解碼器 RNN 的層數\n",
        "      - share_decoder_input_output_embed 通常 decoder 最後輸出的投影矩陣會和輸入 embedding 共用參數\n",
        "  - *dictionary*: fairseq 幫我們做好的 dictionary.\n",
        "  - *embed_tokens*: 事先做好的詞嵌入(nn.Embedding)\n",
        "- 輸入: \n",
        "    - *prev_output_tokens*: 英文的整數序列 e.g. 1, 28, 29, 205, 2 已經 shift 一格的 target\n",
        "    - *encoder_out*: 編碼器的輸出\n",
        "    - *incremental_state*: 這是測試階段為了加速，所以會記錄每個 timestep 的 hidden state 詳見 forward\n",
        "- 輸出: \n",
        "    - *outputs*: decoder 每個 timestep 的 logits，還沒經過 softmax 的分布\n",
        "    - *extra*: 沒用到"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti7QZnZT4raF"
      },
      "source": [
        "class RNNDecoder(FairseqIncrementalDecoder):\n",
        "    def __init__(self, args, dictionary, embed_tokens):\n",
        "        super().__init__(dictionary)\n",
        "        self.embed_tokens = embed_tokens\n",
        "        \n",
        "        assert args.decoder_layers == args.encoder_layers, f\"\"\"seq2seq rnn requires that encoder \n",
        "        and decoder have same layers of rnn. got: {args.encoder_layers, args.decoder_layers}\"\"\"\n",
        "        assert args.decoder_ffn_embed_dim == args.encoder_ffn_embed_dim*2, f\"\"\"seq2seq-rnn requires \n",
        "        that decoder hidden to be 2*encoder hidden dim. got: {args.decoder_ffn_embed_dim, args.encoder_ffn_embed_dim*2}\"\"\"\n",
        "        \n",
        "        self.embed_dim = args.decoder_embed_dim\n",
        "        self.hidden_dim = args.decoder_ffn_embed_dim\n",
        "        self.num_layers = args.decoder_layers\n",
        "        \n",
        "        \n",
        "        self.dropout_in_module = nn.Dropout(args.dropout)\n",
        "        self.rnn = nn.GRU(\n",
        "            self.embed_dim, \n",
        "            self.hidden_dim, \n",
        "            self.num_layers, \n",
        "            dropout=args.dropout, \n",
        "            batch_first=False, \n",
        "            bidirectional=False\n",
        "        )\n",
        "        self.attention = AttentionLayer(\n",
        "            self.embed_dim, self.hidden_dim, self.embed_dim, bias=False\n",
        "        ) \n",
        "        # self.attention = None\n",
        "        self.dropout_out_module = nn.Dropout(args.dropout)\n",
        "        \n",
        "        if self.hidden_dim != self.embed_dim:\n",
        "            self.project_out_dim = nn.Linear(self.hidden_dim, self.embed_dim)\n",
        "        else:\n",
        "            self.project_out_dim = None\n",
        "        \n",
        "        if args.share_decoder_input_output_embed:\n",
        "            self.output_projection = nn.Linear(\n",
        "                self.embed_tokens.weight.shape[1],\n",
        "                self.embed_tokens.weight.shape[0],\n",
        "                bias=False,\n",
        "            )\n",
        "            self.output_projection.weight = self.embed_tokens.weight\n",
        "        else:\n",
        "            self.output_projection = nn.Linear(\n",
        "                self.output_embed_dim, len(dictionary), bias=False\n",
        "            )\n",
        "            nn.init.normal_(\n",
        "                self.output_projection.weight, mean=0, std=self.output_embed_dim ** -0.5\n",
        "            )\n",
        "        \n",
        "    def forward(self, prev_output_tokens, encoder_out, incremental_state=None, **unused):\n",
        "        # 取出encoder的輸出\n",
        "        encoder_outputs, encoder_hiddens, encoder_padding_mask = encoder_out\n",
        "        # outputs:          seq_len x batch x num_directions*hidden\n",
        "        # encoder_hiddens:  num_layers x batch x num_directions*encoder_hidden\n",
        "        # padding_mask:     seq_len x batch\n",
        "        \n",
        "        if incremental_state is not None and len(incremental_state) > 0:\n",
        "            # 有上個timestep留下的資訊，讀進來就可以繼續decode，不用從bos重來\n",
        "            prev_output_tokens = prev_output_tokens[:, -1:]\n",
        "            cache_state = self.get_incremental_state(incremental_state, \"cached_state\")\n",
        "            prev_hiddens = cache_state[\"prev_hiddens\"]\n",
        "        else:\n",
        "            # 沒有incremental state代表這是training或者是test time時的第一步\n",
        "            # 準備seq2seq: 把encoder_hiddens pass進去decoder的hidden states\n",
        "            prev_hiddens = encoder_hiddens\n",
        "        \n",
        "        bsz, seqlen = prev_output_tokens.size()\n",
        "        \n",
        "        # embed tokens\n",
        "        x = self.embed_tokens(prev_output_tokens)\n",
        "        x = self.dropout_in_module(x)\n",
        "\n",
        "        # B x T x C -> T x B x C\n",
        "        x = x.transpose(0, 1)\n",
        "                \n",
        "        # 做decoder-to-encoder attention\n",
        "        if self.attention is not None:\n",
        "            x, attn = self.attention(x, encoder_outputs, encoder_padding_mask)\n",
        "                        \n",
        "        # 過單向RNN\n",
        "        x, final_hiddens = self.rnn(x, prev_hiddens)\n",
        "        # outputs = [sequence len, batch size, hid dim]\n",
        "        # hidden =  [num_layers * directions, batch size  , hid dim]\n",
        "        x = self.dropout_out_module(x)\n",
        "                \n",
        "        # 投影到embedding size (如果hidden 和embed size不一樣，然後share_embedding又設成True,需要額外project一次)\n",
        "        if self.project_out_dim != None:\n",
        "            x = self.project_out_dim(x)\n",
        "        \n",
        "        # 投影到vocab size 的分佈\n",
        "        x = self.output_projection(x)\n",
        "        \n",
        "        # T x B x C -> B x T x C\n",
        "        x = x.transpose(1, 0)\n",
        "        \n",
        "        # 如果是Incremental, 記錄這個timestep的hidden states, 下個timestep讀回來\n",
        "        cache_state = {\n",
        "            \"prev_hiddens\": final_hiddens,\n",
        "        }\n",
        "        self.set_incremental_state(incremental_state, \"cached_state\", cache_state)\n",
        "        \n",
        "        return x, None\n",
        "    \n",
        "    def reorder_incremental_state(\n",
        "        self,\n",
        "        incremental_state,\n",
        "        new_order,\n",
        "    ):\n",
        "        # 這個beam search時會用到，意義並不是很重要\n",
        "        cache_state = self.get_incremental_state(incremental_state, \"cached_state\")\n",
        "        prev_hiddens = cache_state[\"prev_hiddens\"]\n",
        "        prev_hiddens = [p.index_select(0, new_order) for p in prev_hiddens]\n",
        "        cache_state = {\n",
        "            \"prev_hiddens\": torch.stack(prev_hiddens),\n",
        "        }\n",
        "        self.set_incremental_state(incremental_state, \"cached_state\", cache_state)\n",
        "        return"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gsTHVu94raF"
      },
      "source": [
        "## Seq2Seq\n",
        "- 由 **Encoder** 和 **Decoder** 組成\n",
        "- 接收輸入並傳給 **Encoder** \n",
        "- 將 **Encoder** 的輸出傳給 **Decoder**\n",
        "- **Decoder** 根據前幾個 timestep 的輸出和 **Encoder** 輸出進行解碼  \n",
        "- 當解碼完成後，將 **Decoder** 的輸出傳回 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJD90aKZ4raG"
      },
      "source": [
        "class Seq2Seq(FairseqEncoderDecoderModel):\n",
        "    def __init__(self, args, encoder, decoder):\n",
        "        super().__init__(encoder, decoder)\n",
        "        self.args = args\n",
        "    \n",
        "    def forward(\n",
        "        self,\n",
        "        src_tokens,\n",
        "        src_lengths,\n",
        "        prev_output_tokens,\n",
        "        return_all_hiddens: bool = True,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Run the forward pass for an encoder-decoder model.\n",
        "        \"\"\"\n",
        "        encoder_out = self.encoder(\n",
        "            src_tokens, src_lengths=src_lengths, return_all_hiddens=return_all_hiddens\n",
        "        )\n",
        "        logits, extra = self.decoder(\n",
        "            prev_output_tokens,\n",
        "            encoder_out=encoder_out,\n",
        "            src_lengths=src_lengths,\n",
        "            return_all_hiddens=return_all_hiddens,\n",
        "        )\n",
        "        return logits, extra"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkZkJjGO4raG"
      },
      "source": [
        "# 模型初始化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__hN6HGN4raG"
      },
      "source": [
        "# # HINT: transformer 架構\n",
        "# from fairseq.models.transformer import (\n",
        "#     TransformerEncoder, \n",
        "#     TransformerDecoder,\n",
        "# )\n",
        "\n",
        "def build_model(args, task):\n",
        "    \"\"\" 按照參數設定建置模型 \"\"\"\n",
        "    src_dict, tgt_dict = task.source_dictionary, task.target_dictionary\n",
        "\n",
        "    # 詞嵌入\n",
        "    encoder_embed_tokens = nn.Embedding(len(src_dict), args.encoder_embed_dim, src_dict.pad())\n",
        "    decoder_embed_tokens = nn.Embedding(len(tgt_dict), args.decoder_embed_dim, tgt_dict.pad())\n",
        "    \n",
        "    # 編碼器與解碼器\n",
        "    # TODO: 替換成 TransformerEncoder 和 TransformerDecoder\n",
        "    encoder = RNNEncoder(args, src_dict, encoder_embed_tokens)\n",
        "    decoder = RNNDecoder(args, tgt_dict, decoder_embed_tokens)\n",
        "    \n",
        "    # 序列到序列模型\n",
        "    model = Seq2Seq(args, encoder, decoder)\n",
        "    \n",
        "    # 序列到序列模型的初始化很重要 需要特別處理\n",
        "    def init_params(module):\n",
        "        from fairseq.modules import MultiheadAttention\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        if isinstance(module, nn.Embedding):\n",
        "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
        "            if module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "        if isinstance(module, MultiheadAttention):\n",
        "            module.q_proj.weight.data.normal_(mean=0.0, std=0.02)\n",
        "            module.k_proj.weight.data.normal_(mean=0.0, std=0.02)\n",
        "            module.v_proj.weight.data.normal_(mean=0.0, std=0.02)\n",
        "        if isinstance(module, nn.RNNBase):\n",
        "            for name, param in module.named_parameters():\n",
        "                if \"weight\" in name or \"bias\" in name:\n",
        "                    param.data.uniform_(-0.1, 0.1)\n",
        "            \n",
        "    # 初始化模型\n",
        "    model.apply(init_params)\n",
        "    return model"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4vOrwcO4raG"
      },
      "source": [
        "## 設定模型相關參數\n",
        "參考參數\n",
        "\n",
        "|model|embedding dim|encoder ffn|encoder layers|decoder ffn|decoder layers|\n",
        "|-|-|-|-|-|-|\n",
        "|RNN|256|512|1|1024|1|\n",
        "|Transformer|256|1024|4|1024|4|\n",
        "\n",
        "Strong baseline 用的參數可以參考 [Attention is all you need](#vaswani2017) 的 Table 3 的 transformer-base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d31bzk5s4raH"
      },
      "source": [
        "arch_args = Namespace(\n",
        "    encoder_embed_dim=256,\n",
        "    encoder_ffn_embed_dim=512,\n",
        "    encoder_layers=1,\n",
        "    decoder_embed_dim=256,\n",
        "    decoder_ffn_embed_dim=1024,\n",
        "    decoder_layers=1,\n",
        "    share_decoder_input_output_embed=True,\n",
        "    dropout=0.3,\n",
        ")\n",
        "\n",
        "# # HINT: 補上Transformer用的參數\n",
        "# def add_transformer_args(args):\n",
        "#     args.encoder_attention_heads=4\n",
        "#     args.encoder_normalize_before=True\n",
        "    \n",
        "#     args.decoder_attention_heads=4\n",
        "#     args.decoder_normalize_before=True\n",
        "    \n",
        "#     args.activation_fn=\"relu\"\n",
        "#     args.max_source_positions=1024\n",
        "#     args.max_target_positions=1024\n",
        "    \n",
        "#     # 補上我們沒有設定的Transformer預設參數\n",
        "#     from fairseq.models.transformer import base_architecture \n",
        "#     base_architecture(arch_args)\n",
        "\n",
        "# add_transformer_args(arch_args)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_qGKHIC4raH"
      },
      "source": [
        "if config.use_wandb:\n",
        "    wandb.config.update(vars(arch_args))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSKhtAPY4raH",
        "outputId": "d51485ff-26cc-491a-a71b-30b63bcfa2e7"
      },
      "source": [
        "model = build_model(arch_args, task)\n",
        "logger.info(model)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-15 07:56:06 | INFO | hw5.seq2seq | Seq2Seq(\n",
            "  (encoder): RNNEncoder(\n",
            "    (embed_tokens): Embedding(7992, 256, padding_idx=1)\n",
            "    (dropout_in_module): Dropout(p=0.3, inplace=False)\n",
            "    (rnn): GRU(256, 512, dropout=0.3, bidirectional=True)\n",
            "    (dropout_out_module): Dropout(p=0.3, inplace=False)\n",
            "  )\n",
            "  (decoder): RNNDecoder(\n",
            "    (embed_tokens): Embedding(7992, 256, padding_idx=1)\n",
            "    (dropout_in_module): Dropout(p=0.3, inplace=False)\n",
            "    (rnn): GRU(256, 1024, dropout=0.3)\n",
            "    (attention): AttentionLayer(\n",
            "      (input_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
            "      (output_proj): Linear(in_features=1280, out_features=256, bias=False)\n",
            "    )\n",
            "    (dropout_out_module): Dropout(p=0.3, inplace=False)\n",
            "    (project_out_dim): Linear(in_features=1024, out_features=256, bias=True)\n",
            "    (output_projection): Linear(in_features=256, out_features=7992, bias=False)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLce8Eoo4raH"
      },
      "source": [
        "# Optimization 最佳化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuJs4Av_4raI"
      },
      "source": [
        "## Loss: Label Smoothing Regularization\n",
        "* 讓模型學習輸出較不集中的分佈，防止模型過度自信\n",
        "* 有時候Ground Truth並非唯一答案，所以在算loss時，我們會保留一部份機率給正確答案以外的label\n",
        "* 可以有效防止過度擬合\n",
        "\n",
        "code [source](https://fairseq.readthedocs.io/en/latest/_modules/fairseq/criterions/label_smoothed_cross_entropy.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk15oEBf4raI"
      },
      "source": [
        "class LabelSmoothedCrossEntropyCriterion(nn.Module):\n",
        "    def __init__(self, smoothing, ignore_index=None, reduce=True):\n",
        "        super().__init__()\n",
        "        self.smoothing = smoothing\n",
        "        self.ignore_index = ignore_index\n",
        "        self.reduce = reduce\n",
        "    \n",
        "    def forward(self, lprobs, target):\n",
        "        if target.dim() == lprobs.dim() - 1:\n",
        "            target = target.unsqueeze(-1)\n",
        "        # nll: Negative log likelihood，當目標是one-hot時的cross-entropy loss. 以下同 F.nll_loss\n",
        "        nll_loss = -lprobs.gather(dim=-1, index=target)\n",
        "        # 將一部分正確答案的機率分配給其他label 所以當計算cross-entropy時等於把所有label的log prob加起來\n",
        "        smooth_loss = -lprobs.sum(dim=-1, keepdim=True)\n",
        "        if self.ignore_index is not None:\n",
        "            pad_mask = target.eq(self.ignore_index)\n",
        "            nll_loss.masked_fill_(pad_mask, 0.0)\n",
        "            smooth_loss.masked_fill_(pad_mask, 0.0)\n",
        "        else:\n",
        "            nll_loss = nll_loss.squeeze(-1)\n",
        "            smooth_loss = smooth_loss.squeeze(-1)\n",
        "        if self.reduce:\n",
        "            nll_loss = nll_loss.sum()\n",
        "            smooth_loss = smooth_loss.sum()\n",
        "        # 計算cross-entropy時 加入分配給其他label的loss\n",
        "        eps_i = self.smoothing / lprobs.size(-1)\n",
        "        loss = (1.0 - self.smoothing) * nll_loss + eps_i * smooth_loss\n",
        "        return loss\n",
        "\n",
        "# 一般都用0.1效果就很好了\n",
        "criterion = LabelSmoothedCrossEntropyCriterion(\n",
        "    smoothing=0.1,\n",
        "    ignore_index=task.target_dictionary.pad(),\n",
        ")"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLdjJVkW4raI"
      },
      "source": [
        "## Optimizer: Adam + lr scheduling\n",
        "Inverse square root 排程對於訓練 Transformer 時的穩定性很重要，後來也用在 RNN 上。\n",
        "根據底下公式來更新 learning rate，前期線性增長，後期根據更新步數方根的倒數來遞減。\n",
        "$$lrate = d_{\\text{model}}^{-0.5}\\cdot\\min({step\\_num}^{-0.5},{step\\_num}\\cdot{warmup\\_steps}^{-1.5})$$\n",
        "code [source](https://nlp.seas.harvard.edu/2018/04/03/attention.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZpWj_i04raI"
      },
      "source": [
        "class NoamOpt:\n",
        "    \"Optim wrapper that implements rate.\"\n",
        "    def __init__(self, model_size, factor, warmup, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        self._step = 0\n",
        "        self.warmup = warmup\n",
        "        self.factor = factor\n",
        "        self.model_size = model_size\n",
        "        self._rate = 0\n",
        "    \n",
        "    @property\n",
        "    def param_groups(self):\n",
        "        return self.optimizer.param_groups\n",
        "        \n",
        "    def multiply_grads(self, c):\n",
        "        \"\"\"Multiplies grads by a constant *c*.\"\"\"                \n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is not None:\n",
        "                    p.grad.data.mul_(c)\n",
        "        \n",
        "    def step(self):\n",
        "        \"Update parameters and rate\"\n",
        "        self._step += 1\n",
        "        rate = self.rate()\n",
        "        for p in self.param_groups:\n",
        "            p['lr'] = rate\n",
        "        self._rate = rate\n",
        "        self.optimizer.step()\n",
        "        \n",
        "    def rate(self, step = None):\n",
        "        \"Implement `lrate` above\"\n",
        "        if step is None:\n",
        "            step = self._step\n",
        "        return 0 if not step else self.factor * \\\n",
        "            (self.model_size ** (-0.5) *\n",
        "            min(step ** (-0.5), step * self.warmup ** (-1.5)))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NKDvxzd4raJ"
      },
      "source": [
        "## 排程視覺化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "vSBIEgvf4raJ",
        "outputId": "9177ba00-ec6c-4521-f769-7f23bf454af2"
      },
      "source": [
        "optimizer = NoamOpt(\n",
        "    model_size=arch_args.encoder_embed_dim, \n",
        "    factor=config.lr_factor, \n",
        "    warmup=config.lr_warmup, \n",
        "    optimizer=torch.optim.AdamW(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9, weight_decay=0.0001))\n",
        "plt.plot(np.arange(1, 100000), [optimizer.rate(i) for i in range(1, 100000)])\n",
        "plt.legend([f\"{optimizer.model_size}:{optimizer.warmup}\"])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMMbHCbe4raJ"
      },
      "source": [
        "# 訓練步驟"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtjMMH6i4raJ"
      },
      "source": [
        "## Training 訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR0OLCRS4raJ"
      },
      "source": [
        "from fairseq.data import iterators\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "def train_one_epoch(epoch_itr, model, task, criterion, optimizer, accum_steps=1):\n",
        "    itr = epoch_itr.next_epoch_itr(shuffle=True)\n",
        "    itr = iterators.GroupedIterator(itr, accum_steps) # 梯度累積: 每 accum_steps 個 sample 更新一次\n",
        "    \n",
        "    stats = {\"loss\": []}\n",
        "    scaler = GradScaler() # 混和精度訓練 automatic mixed precision (amp) \n",
        "    \n",
        "    model.train()\n",
        "    progress = tqdm.tqdm(itr, desc=f\"train epoch {epoch_itr.epoch}\", leave=False)\n",
        "    for samples in progress:\n",
        "        model.zero_grad()\n",
        "        accum_loss = 0\n",
        "        sample_size = 0\n",
        "        # 梯度累積: 每 accum_steps 個 sample 更新一次\n",
        "        for i, sample in enumerate(samples):\n",
        "            if i == 1:\n",
        "                # emptying the CUDA cache after the first step can reduce the chance of OOM\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "            sample = utils.move_to_cuda(sample, device=device)\n",
        "            target = sample[\"target\"]\n",
        "            sample_size_i = sample[\"ntokens\"]\n",
        "            sample_size += sample_size_i\n",
        "            \n",
        "            # 混和精度訓練 \n",
        "            with autocast():\n",
        "                net_output = model.forward(**sample[\"net_input\"])\n",
        "                lprobs = F.log_softmax(net_output[0], -1)            \n",
        "                loss = criterion(lprobs.view(-1, lprobs.size(-1)), target.view(-1))\n",
        "                \n",
        "                # logging\n",
        "                accum_loss += loss.item()\n",
        "                # back-prop\n",
        "                scaler.scale(loss).backward()                \n",
        "        \n",
        "        scaler.unscale_(optimizer)\n",
        "        optimizer.multiply_grads(1 / (sample_size or 1.0)) # (sample_size or 1.0) handles the case of a zero gradient\n",
        "        gnorm = nn.utils.clip_grad_norm_(model.parameters(), config.clip_norm) # 梯度裁剪 防止梯度爆炸\n",
        "        \n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        \n",
        "        # logging\n",
        "        loss_print = accum_loss/sample_size\n",
        "        stats[\"loss\"].append(loss_print)\n",
        "        progress.set_postfix(loss=loss_print)\n",
        "        if config.use_wandb:\n",
        "            wandb.log({\n",
        "                \"train/loss\": loss_print,\n",
        "                \"train/grad_norm\": gnorm.item(),\n",
        "                \"train/lr\": optimizer.rate(),\n",
        "                \"train/sample_size\": sample_size,\n",
        "            })\n",
        "        \n",
        "    loss_print = np.mean(stats[\"loss\"])\n",
        "    logger.info(f\"training loss: {loss_print:.4f}\")\n",
        "    return stats"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkiOG0xC4raK"
      },
      "source": [
        "## Validation & Inference 檢驗和推論\n",
        "為防止訓練發生過度擬合，每過一段時間要做一次檢測，計算模型在未看過的資料上的表現。\n",
        "- 過程基本上和training一樣，另外加上 inference\n",
        "- 檢驗完畢可順便儲存模型參數\n",
        "\n",
        "單看 validation loss，我們很難知道模型真實的效能\n",
        "- 直接用當前模型去生成翻譯結果 (hypothesis)，再和正確答案 (reference) 計算 BLEU score\n",
        "- 也可用肉眼看翻譯結果的好壞\n",
        "- 我們用 fairseq 寫好的 sequence generator 來進行 beam search 生成翻譯結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92T_8BWu4raK"
      },
      "source": [
        "# fairseq 的 beam search generator\n",
        "# 給定模型和輸入序列，用 beam search 生成翻譯結果\n",
        "sequence_generator = task.build_generator([model], config)\n",
        "\n",
        "def decode(toks, dictionary):\n",
        "    # 從 Tensor 轉成人看得懂的句子\n",
        "    s = dictionary.string(\n",
        "        toks.int().cpu(),\n",
        "        config.post_process,\n",
        "    )\n",
        "    return s if s else \"<unk>\"\n",
        "\n",
        "def inference_step(sample, model):\n",
        "    gen_out = sequence_generator.generate([model], sample)\n",
        "    srcs = []\n",
        "    hyps = []\n",
        "    refs = []\n",
        "    for i in range(len(gen_out)):\n",
        "        # 對於每個 sample, 收集輸入，輸出和參考答案，稍後計算 BLEU\n",
        "        srcs.append(decode(\n",
        "            utils.strip_pad(sample[\"net_input\"][\"src_tokens\"][i], task.source_dictionary.pad()), \n",
        "            task.source_dictionary,\n",
        "        ))\n",
        "        hyps.append(decode(\n",
        "            gen_out[i][0][\"tokens\"], # 0 代表取出 beam 內分數第一的輸出結果\n",
        "            task.target_dictionary,\n",
        "        ))\n",
        "        refs.append(decode(\n",
        "            utils.strip_pad(sample[\"target\"][i], task.target_dictionary.pad()), \n",
        "            task.target_dictionary,\n",
        "        ))\n",
        "    return srcs, hyps, refs"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLzhoPM-4raK"
      },
      "source": [
        "import shutil\n",
        "import sacrebleu\n",
        "\n",
        "def validate(model, task, criterion, log_to_wandb=True):\n",
        "    logger.info('begin validation')\n",
        "    itr = load_data_iterator(task, \"valid\", 1, config.max_tokens, config.num_workers).next_epoch_itr(shuffle=False)\n",
        "    \n",
        "    stats = {\"loss\":[], \"bleu\": 0, \"srcs\":[], \"hyps\":[], \"refs\":[]}\n",
        "    srcs = []\n",
        "    hyps = []\n",
        "    refs = []\n",
        "    \n",
        "    model.eval()\n",
        "    progress = tqdm.tqdm(itr, desc=f\"validation\", leave=False)\n",
        "    with torch.no_grad():\n",
        "        for i, sample in enumerate(progress):\n",
        "            # validation loss\n",
        "            sample = utils.move_to_cuda(sample, device=device)\n",
        "            net_output = model.forward(**sample[\"net_input\"])\n",
        "\n",
        "            lprobs = F.log_softmax(net_output[0], -1)\n",
        "            target = sample[\"target\"]\n",
        "            sample_size = sample[\"ntokens\"]\n",
        "            loss = criterion(lprobs.view(-1, lprobs.size(-1)), target.view(-1)) / sample_size\n",
        "            progress.set_postfix(valid_loss=loss.item())\n",
        "            stats[\"loss\"].append(loss)\n",
        "            \n",
        "            # 進行推論\n",
        "            s, h, r = inference_step(sample, model)\n",
        "            srcs.extend(s)\n",
        "            hyps.extend(h)\n",
        "            refs.extend(r)\n",
        "            \n",
        "    tok = 'zh' if task.cfg.target_lang == 'zh' else '13a'\n",
        "    stats[\"loss\"] = torch.stack(stats[\"loss\"]).mean().item()\n",
        "    stats[\"bleu\"] = sacrebleu.corpus_bleu(hyps, [refs], tokenize=tok) # 計算BLEU score\n",
        "    stats[\"srcs\"] = srcs\n",
        "    stats[\"hyps\"] = hyps\n",
        "    stats[\"refs\"] = refs\n",
        "    \n",
        "    if config.use_wandb and log_to_wandb:\n",
        "        wandb.log({\n",
        "            \"valid/loss\": stats[\"loss\"],\n",
        "            \"valid/bleu\": stats[\"bleu\"].score,\n",
        "        }, commit=False)\n",
        "    \n",
        "    showid = np.random.randint(len(hyps))\n",
        "    logger.info(\"example source: \" + srcs[showid])\n",
        "    logger.info(\"example hypothesis: \" + hyps[showid])\n",
        "    logger.info(\"example reference: \" + refs[showid])\n",
        "    \n",
        "    # show bleu results\n",
        "    logger.info(f\"validation loss:\\t{stats['loss']:.4f}\")\n",
        "    logger.info(stats[\"bleu\"].format())\n",
        "    return stats"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R56dlCve4raL"
      },
      "source": [
        "# 儲存及載入模型參數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulzg4GvH4raL"
      },
      "source": [
        "def validate_and_save(model, task, criterion, optimizer, epoch, save=True):   \n",
        "    stats = validate(model, task, criterion)\n",
        "    bleu = stats['bleu']\n",
        "    loss = stats['loss']\n",
        "    if save:\n",
        "        # save epoch checkpoints\n",
        "        savedir = Path(config.savedir).absolute()\n",
        "        savedir.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        check = {\n",
        "            \"model\": model.state_dict(),\n",
        "            \"stats\": {\"bleu\": bleu.score, \"loss\": loss},\n",
        "            \"optim\": {\"step\": optimizer._step}\n",
        "        }\n",
        "        torch.save(check, savedir/f\"checkpoint{epoch}.pt\")\n",
        "        shutil.copy(savedir/f\"checkpoint{epoch}.pt\", savedir/f\"checkpoint_last.pt\")\n",
        "        logger.info(f\"saved epoch checkpoint: {savedir}/checkpoint{epoch}.pt\")\n",
        "    \n",
        "        # save epoch samples\n",
        "        with open(savedir/f\"samples{epoch}.{config.source_lang}-{config.target_lang}.txt\", \"w\") as f:\n",
        "            for s, h in zip(stats[\"srcs\"], stats[\"hyps\"]):\n",
        "                f.write(f\"{s}\\t{h}\\n\")\n",
        "\n",
        "        # get best valid bleu    \n",
        "        if getattr(validate_and_save, \"best_bleu\", 0) < bleu.score:\n",
        "            validate_and_save.best_bleu = bleu.score\n",
        "            torch.save(check, savedir/f\"checkpoint_best.pt\")\n",
        "            \n",
        "        del_file = savedir / f\"checkpoint{epoch - config.keep_last_epochs}.pt\"\n",
        "        if del_file.exists():\n",
        "            del_file.unlink()\n",
        "    \n",
        "    return stats\n",
        "\n",
        "def try_load_checkpoint(model, optimizer=None, name=None):\n",
        "    name = name if name else \"checkpoint_last.pt\"\n",
        "    checkpath = Path(config.savedir)/name\n",
        "    if checkpath.exists():\n",
        "        check = torch.load(checkpath)\n",
        "        model.load_state_dict(check[\"model\"])\n",
        "        stats = check[\"stats\"]\n",
        "        step = \"unknown\"\n",
        "        if optimizer != None:\n",
        "            optimizer._step = step = check[\"optim\"][\"step\"]\n",
        "        logger.info(f\"loaded checkpoint {checkpath}: step={step} loss={stats['loss']} bleu={stats['bleu']}\")\n",
        "    else:\n",
        "        logger.info(f\"no checkpoints found at {checkpath}!\")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF6-jCl54raL"
      },
      "source": [
        "# 主程式\n",
        "## 訓練迴圈"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T6GTlKQ4raM"
      },
      "source": [
        "model = model.to(device=device)\n",
        "criterion = criterion.to(device=device)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiztkFXp4raM",
        "outputId": "b8ed0c13-079c-47ab-ed0f-f21acf0e6fa4"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat May 15 07:56:46 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    26W /  70W |   1116MiB / 15109MiB |      2%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hnJ7uWu4raM",
        "outputId": "afa0dac3-d756-4170-d8a9-fd8f55d34196"
      },
      "source": [
        "logger.info(\"task: {}\".format(task.__class__.__name__))\n",
        "logger.info(\"encoder: {}\".format(model.encoder.__class__.__name__))\n",
        "logger.info(\"decoder: {}\".format(model.decoder.__class__.__name__))\n",
        "logger.info(\"criterion: {}\".format(criterion.__class__.__name__))\n",
        "logger.info(\"optimizer: {}\".format(optimizer.__class__.__name__))\n",
        "logger.info(\n",
        "    \"num. model params: {:,} (num. trained: {:,})\".format(\n",
        "        sum(p.numel() for p in model.parameters()),\n",
        "        sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
        "    )\n",
        ")\n",
        "logger.info(f\"max tokens per batch = {config.max_tokens}, accumulate steps = {config.accum_steps}\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-15 07:56:46 | INFO | hw5.seq2seq | task: TranslationTask\n",
            "2021-05-15 07:56:46 | INFO | hw5.seq2seq | encoder: RNNEncoder\n",
            "2021-05-15 07:56:46 | INFO | hw5.seq2seq | decoder: RNNDecoder\n",
            "2021-05-15 07:56:46 | INFO | hw5.seq2seq | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2021-05-15 07:56:46 | INFO | hw5.seq2seq | optimizer: NoamOpt\n",
            "2021-05-15 07:56:46 | INFO | hw5.seq2seq | num. model params: 11,247,872 (num. trained: 11,247,872)\n",
            "2021-05-15 07:56:46 | INFO | hw5.seq2seq | max tokens per batch = 8192, accumulate steps = 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "34edba646d974707a2eba26d653b8b42",
            "2529a01e85744576bc03e44590cbb1ec",
            "1d9e2e920bfe40f984f07f09244ff605",
            "b5d4961fb2114f139e6464d86f70063d",
            "c443dbd9b8b54582a2949658bfdaa6a5",
            "c4850abb8ecc433fa245a1dea12c0640",
            "feb90fa084154d6298dca215edb234c2",
            "ae9d76b5c783458e827190be5328f877",
            "48f0bfe8918248f5b62495cab74aa1c7",
            "6d78428708994195ac53081902d58829",
            "aff3a47377a5423b8a402a0bd45b0c39",
            "1ddac745fb0648aa8d4e19ec23d62fe9",
            "fb71dc594353406cb89ac388444283fb",
            "11035c3f04f946198117493c362acf5d",
            "32c1e127f70f4cd88f79005ffa74fb96",
            "6aafc63cf2c44150b104d3b6687a9e44",
            "6eabcbd9923047daa138479dcae0b848",
            "45f39f1ac3784453ac13f54a7b2d83f9",
            "ae3f0f757f2b4e13a44262f2312878be",
            "534f2cf8702545dd8d12d574b66dec8a",
            "d128af55cabe4cc18701c2d9c2ef9530",
            "00282f7605464657916f3f4f336315a6",
            "3716528720834940b1f57f4e0c0a5b16",
            "35dd289ac1da43b8a5a26ac1a44bba5f",
            "63d26e73c0954ebaa336d331fa042f18",
            "1ff55dff1d5e4fee96c3ef30370c1217",
            "7ea2d830f06341e7b80553bf437b3ba6",
            "60ec6ff57155459e8cdf31b734d20e19",
            "68849516a44f458e8aaa5518f8c5492e",
            "89b0df52f69241508d209706297cd9ae",
            "87518f4fe1d6427589ac902375e3b17f",
            "b6d4e78504b1424392bda8bce2c891b9",
            "55a8b17236c04dacb01df368edcb8d29",
            "9111c9cfadf54bd29c9001b5b095c038",
            "80e685c8e815489188eb8d468f31b90c",
            "f008cecee2584fb5a2fde9ecccb863c8",
            "5abc383185d34a42af1742d21a588e6a",
            "2cdbe8f119534f389666d8549eb1188e",
            "4529b69660554867a67b297c2ea6f74d",
            "fc44d93044824ecd9dfadc1720594ee7",
            "0ba96df2e2ae4d878f925380036d5cb0",
            "458e3f044b8f43dbb957954560d4c141",
            "2971a305446249d3a77f51e3ff795ed6",
            "22d0cbee3d00442e91e507da828c4729",
            "0bd550c80bf84e7f826abe342d42037f",
            "5dcc52146c364d2fa99e6cc6293fdb3c",
            "956c48979ec64fec84127b689c71ccb2",
            "e6ed08d660b54d878b9c2ccf96567e80",
            "9ab63514adb8489eb4cfd3536ee14192",
            "20b93187f221438a9e29ebf9c3111a4d",
            "3819c78cd18f49faa73cb0bf8b5e3e71",
            "5c0990dab20c425388a2994ce0c70af6",
            "7390e8efe9c545529e498278cf7db0fb",
            "755c30b10ae943b7bd2031b5fdcf9915",
            "aac0c860d70344f69bcac80378d9ee8f",
            "0e50b32a845f4a07983b46468c1497cc",
            "fce2a0578fa641d2b28ea6839fc264c2",
            "a6ae96b1b5974223be47204d38e5dfd6",
            "7a5486d768594eb0bada30c0ced62cbb",
            "b430a79e9bbd4c03bc89e6efbbf52c30",
            "e8e24fe3acb945aa83cc279d1013c7e8",
            "da9e1c5768634c6aa286c94dd8b45424",
            "c9613e4c4b4c44ab8455e97a64275a07",
            "ac3dce7105bf4d08907d2d164b77d5bf",
            "6a446ee961864bec988a1961c05abcdc",
            "a73578a49abe432d9273852a30934e0f",
            "f0ea8e49f53e496d94d5dbccc9e04946",
            "69a8d02e763946bfb85620caa11c0ec2",
            "515f36e9bb644504ae6cfccda11e5216",
            "247a1bed65ea4ee0817dea7680e65a44",
            "833b2c6456234127bbdf9d30d52e69f0",
            "4f0399de85e946158ff77ec5df45fbe9"
          ]
        },
        "id": "LaTc29-M4raM",
        "outputId": "685a5adc-103c-4b85-b354-a4c3d4004d65"
      },
      "source": [
        "epoch_itr = load_data_iterator(task, \"train\", config.start_epoch, config.max_tokens, config.num_workers)\n",
        "try_load_checkpoint(model, optimizer, name=config.resume)\n",
        "while epoch_itr.next_epoch_idx <= config.max_epoch:\n",
        "    # train for one epoch\n",
        "    train_one_epoch(epoch_itr, model, task, criterion, optimizer, config.accum_steps)\n",
        "    stats = validate_and_save(model, task, criterion, optimizer, epoch=epoch_itr.epoch)\n",
        "    logger.info(\"end of epoch {}\".format(epoch_itr.epoch))    \n",
        "    epoch_itr = load_data_iterator(task, \"train\", epoch_itr.next_epoch_idx, config.max_tokens, config.num_workers)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-15 07:56:46 | WARNING | fairseq.tasks.fairseq_task | 1 samples have invalid sizes and will be skipped, max_positions=(1024, 1024), first few sample ids=[326665]\n",
            "2021-05-15 07:56:46 | INFO | hw5.seq2seq | no checkpoints found at checkpoints/rnn/checkpoint_last.pt!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34edba646d974707a2eba26d653b8b42",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='train epoch 1', max=798.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r2021-05-15 07:58:43 | INFO | hw5.seq2seq | training loss: 7.0787\n",
            "2021-05-15 07:58:43 | INFO | hw5.seq2seq | begin validation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48f0bfe8918248f5b62495cab74aa1c7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='validation', max=23.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r2021-05-15 07:59:09 | INFO | hw5.seq2seq | example source: the system also recognizes iconic gestures such as the \" take a picture \" gesture , and then takes a picture of whatever is in front of you .\n",
            "2021-05-15 07:59:09 | INFO | hw5.seq2seq | example hypothesis: 我們 , 我 , \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"\n",
            "2021-05-15 07:59:09 | INFO | hw5.seq2seq | example reference: 這個系統還能辨識出具象徵性的手勢例如這個拍照的動作 , 它會直接拍下你面前的事物 。\n",
            "2021-05-15 07:59:09 | INFO | hw5.seq2seq | validation loss:\t6.5410\n",
            "2021-05-15 07:59:09 | INFO | hw5.seq2seq | BLEU = 0.06 7.2/1.0/0.0/0.0 (BP = 0.816 ratio = 0.831 hyp_len = 92272 ref_len = 111005)\n",
            "2021-05-15 07:59:09 | INFO | hw5.seq2seq | saved epoch checkpoint: /content/checkpoints/rnn/checkpoint1.pt\n",
            "2021-05-15 07:59:09 | INFO | hw5.seq2seq | end of epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6eabcbd9923047daa138479dcae0b848",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='train epoch 2', max=798.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r2021-05-15 08:01:10 | INFO | hw5.seq2seq | training loss: 6.3078\n",
            "2021-05-15 08:01:10 | INFO | hw5.seq2seq | begin validation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63d26e73c0954ebaa336d331fa042f18",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='validation', max=23.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r2021-05-15 08:01:30 | INFO | hw5.seq2seq | example source: anyway , after that whole , big , long explanation , the only question he had for me and this is not a joke is , are we paying royalties after we broadcast music of michael jackson ?\n",
            "2021-05-15 08:01:30 | INFO | hw5.seq2seq | example hypothesis: 每年 , 我說 , \" 嗯 , \" 嗯 , \" 嗯 ? \" 是 \"  \" 的 \"  \" 的 \"  \" 的 \"  \" 的 \"  \" 的 \"  \" 的 \"  \" 的 \"  \" 的 \"\n",
            "2021-05-15 08:01:30 | INFO | hw5.seq2seq | example reference: 總之 , 在一番長篇說明後 , 他向我提及唯一的問題是這不是笑話我們播放麥克.傑克遜的歌是否須支付版權費 ?\n",
            "2021-05-15 08:01:30 | INFO | hw5.seq2seq | validation loss:\t5.9493\n",
            "2021-05-15 08:01:30 | INFO | hw5.seq2seq | BLEU = 0.76 18.4/2.6/0.4/0.1 (BP = 0.684 ratio = 0.725 hyp_len = 80424 ref_len = 111005)\n",
            "2021-05-15 08:01:30 | INFO | hw5.seq2seq | saved epoch checkpoint: /content/checkpoints/rnn/checkpoint2.pt\n",
            "2021-05-15 08:01:30 | INFO | hw5.seq2seq | end of epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55a8b17236c04dacb01df368edcb8d29",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='train epoch 3', max=798.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r2021-05-15 08:03:31 | INFO | hw5.seq2seq | training loss: 5.7674\n",
            "2021-05-15 08:03:31 | INFO | hw5.seq2seq | begin validation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ba96df2e2ae4d878f925380036d5cb0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='validation', max=23.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r2021-05-15 08:03:52 | INFO | hw5.seq2seq | example source: how are you going to replicate ? \"\n",
            "2021-05-15 08:03:52 | INFO | hw5.seq2seq | example hypothesis: 你要做什麼 ? 」\n",
            "2021-05-15 08:03:52 | INFO | hw5.seq2seq | example reference: 你們會如何複製經驗 ?\n",
            "2021-05-15 08:03:52 | INFO | hw5.seq2seq | validation loss:\t5.4028\n",
            "2021-05-15 08:03:52 | INFO | hw5.seq2seq | BLEU = 1.85 20.1/4.2/1.1/0.3 (BP = 0.815 ratio = 0.830 hyp_len = 92144 ref_len = 111005)\n",
            "2021-05-15 08:03:52 | INFO | hw5.seq2seq | saved epoch checkpoint: /content/checkpoints/rnn/checkpoint3.pt\n",
            "2021-05-15 08:03:52 | INFO | hw5.seq2seq | end of epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ab63514adb8489eb4cfd3536ee14192",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='train epoch 4', max=798.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r2021-05-15 08:05:53 | INFO | hw5.seq2seq | training loss: 5.3278\n",
            "2021-05-15 08:05:53 | INFO | hw5.seq2seq | begin validation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fce2a0578fa641d2b28ea6839fc264c2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='validation', max=23.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r2021-05-15 08:06:16 | INFO | hw5.seq2seq | example source: at the moment , we have successfully grown tomatoes .\n",
            "2021-05-15 08:06:16 | INFO | hw5.seq2seq | example hypothesis: 此時 , 我們有非常大規模的進化 。\n",
            "2021-05-15 08:06:16 | INFO | hw5.seq2seq | example reference: 此刻 , 我們已經成功種出了蕃茄 。\n",
            "2021-05-15 08:06:16 | INFO | hw5.seq2seq | validation loss:\t4.9454\n",
            "2021-05-15 08:06:16 | INFO | hw5.seq2seq | BLEU = 4.87 24.4/7.5/2.8/1.1 (BP = 1.000 ratio = 1.091 hyp_len = 121077 ref_len = 111005)\n",
            "2021-05-15 08:06:16 | INFO | hw5.seq2seq | saved epoch checkpoint: /content/checkpoints/rnn/checkpoint4.pt\n",
            "2021-05-15 08:06:16 | INFO | hw5.seq2seq | end of epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a446ee961864bec988a1961c05abcdc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='train epoch 5', max=798.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-fe682ee74cf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mepoch_itr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_epoch_idx\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_itr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_itr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"end of epoch {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_itr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-e3d66598e8c4>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch_itr, model, task, criterion, optimizer, accum_steps)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0maccum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;31m# back-prop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3Ouqfff4raN"
      },
      "source": [
        "# Submission 繳交檔案"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWN-MYcJ4raN"
      },
      "source": [
        "# 把幾個 checkpoint 平均起來可以達到 ensemble 的效果\n",
        "checkdir=config.savedir\n",
        "!python ./fairseq/scripts/average_checkpoints.py \\\n",
        "--inputs {checkdir} \\\n",
        "--num-epoch-checkpoints 5 \\\n",
        "--output {checkdir}/avg_last_5_checkpoint.pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAfRlSPL4raN"
      },
      "source": [
        "## 確認生成繳交檔案的模型參數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1XHU34w4raN"
      },
      "source": [
        "# checkpoint_last.pt : 最後一次檢驗的檔案\n",
        "# checkpoint_best.pt : 檢驗 BLEU 最高的檔案\n",
        "# avg_last_5_checkpoint.pt:　最5後個檔案平均\n",
        "try_load_checkpoint(model, name=\"avg_last_5_checkpoint.pt\")\n",
        "validate(model, task, criterion, log_to_wandb=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6SikdOk4raN"
      },
      "source": [
        "## 進行預測"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABytDR9l4raO"
      },
      "source": [
        "def generate_prediction(model, task, split=\"test\", outfile=\"./prediction.txt\"):    \n",
        "    task.load_dataset(split=split, epoch=1)\n",
        "    itr = load_data_iterator(task, split, 1, config.max_tokens, config.num_workers).next_epoch_itr(shuffle=False)\n",
        "    \n",
        "    idxs = []\n",
        "    hyps = []\n",
        "\n",
        "    model.eval()\n",
        "    progress = tqdm.tqdm(itr, desc=f\"prediction\")\n",
        "    with torch.no_grad():\n",
        "        for i, sample in enumerate(progress):\n",
        "            # validation loss\n",
        "            sample = utils.move_to_cuda(sample, device=device)\n",
        "\n",
        "            # 進行推論\n",
        "            s, h, r = inference_step(sample, model)\n",
        "            \n",
        "            hyps.extend(h)\n",
        "            idxs.extend(list(sample['id']))\n",
        "            \n",
        "    # 根據 preprocess 時的順序排列\n",
        "    hyps = [x for _,x in sorted(zip(idxs,hyps))]\n",
        "    \n",
        "    with open(outfile, \"w\") as f:\n",
        "        for h in hyps:\n",
        "            f.write(h+\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ghjoKcP4raO"
      },
      "source": [
        "generate_prediction(model, task)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMeeHYXE4raO"
      },
      "source": [
        "raise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df2O7An44raO"
      },
      "source": [
        "# Back-translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mXUqHS64raP"
      },
      "source": [
        "## 訓練一個反向的翻譯模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nUK25ve4raP"
      },
      "source": [
        "1. 將實驗的參數設定表中(config)的source_lang與target_lang互相交換\n",
        "2. 將實驗的參數設定表中(config)的savedir更改(ex. \"./checkpoints/rnn-back\")\n",
        "3. 訓練一個反向模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIwcwxdL4raP"
      },
      "source": [
        "## 利用反向模型生成額外資料"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHYRSmBb4raP"
      },
      "source": [
        "### 下載 monolingual data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMtPusEn4raP"
      },
      "source": [
        "mono_dataset_name = 'mono'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp8sQvqZ4raQ"
      },
      "source": [
        "mono_prefix = Path(data_dir).absolute() / mono_dataset_name\n",
        "mono_prefix.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "urls = (\n",
        "    '\"https://onedrive.live.com/download?cid=3E549F3B24B238B4&resid=3E549F3B24B238B4%214986&authkey=AANUKbGfZx0kM80\"',\n",
        "# # If the above links die, use the following instead. \n",
        "#     \"https://www.csie.ntu.edu.tw/~r09922057/ML2021-hw5/ted_zh_corpus.deduped.gz\",\n",
        "# # If the above links die, use the following instead. \n",
        "#     \"https://mega.nz/#!vMNnDShR!4eHDxzlpzIpdpeQTD-htatU_C7QwcBTwGDaSeBqH534\",\n",
        ")\n",
        "file_names = (\n",
        "    'ted_zh_corpus.deduped.gz',\n",
        ")\n",
        "\n",
        "for u, f in zip(urls, file_names):\n",
        "    path = mono_prefix/f\n",
        "    if not path.exists():\n",
        "        if 'mega' in u:\n",
        "            !megadl {u} --path {path}\n",
        "        else:\n",
        "            !wget {u} -O {path}\n",
        "    else:\n",
        "        print(f'{f} is exist, skip downloading')\n",
        "    if path.suffix == \".tgz\":\n",
        "        !tar -xvf {path} -C {prefix}\n",
        "    elif path.suffix == \".zip\":\n",
        "        !unzip -o {path} -d {prefix}\n",
        "    elif path.suffix == \".gz\":\n",
        "        !gzip -fkd {path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUm1NKJn4raQ"
      },
      "source": [
        "### TODO: 清理資料集\n",
        "\n",
        "1. 將太長、太短的句子移除\n",
        "2. 統一標點符號\n",
        "\n",
        "hint: 可以使用clean_s()來協助"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foHR3nHo4raQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4iqgDEY4raQ"
      },
      "source": [
        "### TODO: Subword Units\n",
        "\n",
        "用反向模型的 spm model 將資料切成 subword units\n",
        "\n",
        "hint: spm model 的路徑為 DATA/raw-data/\\[dataset\\]/spm\\[vocab_num\\].model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMlwrfPc4raR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZsBCeYe4raR"
      },
      "source": [
        "### Binarize\n",
        "\n",
        "使用fairseq將資料轉為binary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vavLCs44raR"
      },
      "source": [
        "binpath = Path('./DATA/data-bin', mono_dataset_name)\n",
        "src_dict_file = './DATA/data-bin/ted2020/dict.en.txt'\n",
        "tgt_dict_file = src_dict_file\n",
        "monopref = str(mono_prefix/\"mono.tok\") # whatever filepath you get after applying subword tokenization\n",
        "if binpath.exists():\n",
        "    print(binpath, \"exists, will not overwrite!\")\n",
        "else:\n",
        "    !python -m fairseq_cli.preprocess\\\n",
        "        --source-lang 'zh'\\\n",
        "        --target-lang 'en'\\\n",
        "        --trainpref {monopref}\\\n",
        "        --destdir {binpath}\\\n",
        "        --srcdict {src_dict_file}\\\n",
        "        --tgtdict {tgt_dict_file}\\\n",
        "        --workers 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Rt8jMk64raR"
      },
      "source": [
        "### TODO: 生成反向翻譯資料\n",
        "\n",
        "將 binarized data 加入原本的資料夾中並用一個 split_name 取名\n",
        "\n",
        "ex. ./DATA/data-bin/ted2020/\\[split_name\\].zh-en.\\[\"en\", \"zh\"\\].\\[\"bin\", \"idx\"\\]\n",
        "\n",
        "便可以使用 generate_prediction(model, task, split=\"split_name\")來產生翻譯資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtQvCgD64raS"
      },
      "source": [
        "# 將 binarized data 加入原本的資料夾中並用一個 split_name 取名\n",
        "# ex. ./DATA/data-bin/ted2020/\\[split_name\\].zh-en.\\[\"en\", \"zh\"\\].\\[\"bin\", \"idx\"\\]\n",
        "!cp ./DATA/data-bin/mono/train.zh-en.zh.bin ./DATA/data-bin/ted2020/mono.zh-en.zh.bin\n",
        "!cp ./DATA/data-bin/mono/train.zh-en.zh.idx ./DATA/data-bin/ted2020/mono.zh-en.zh.idx\n",
        "!cp ./DATA/data-bin/mono/train.zh-en.en.bin ./DATA/data-bin/ted2020/mono.zh-en.en.bin\n",
        "!cp ./DATA/data-bin/mono/train.zh-en.en.idx ./DATA/data-bin/ted2020/mono.zh-en.en.idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvG8oaFU4raS"
      },
      "source": [
        "# hint: 用反向模型在 split='mono' 上進行預測，生成 prediction_file\n",
        "# generate_prediction( ... ,split=... ,outfile=... )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LynDq3O84raS"
      },
      "source": [
        "### TODO: 產生新的dataset\n",
        "\n",
        "1. 將翻譯出來的資料與原先的訓練資料結合\n",
        "2. 使用之前的spm model切出成Subword Units\n",
        "3. 重新使用fairseq將資料轉為binary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvgqtvbx4raS"
      },
      "source": [
        "# 合併剛剛生成的 prediction_file (.en) 以及中文 mono.zh (.zh)\n",
        "# \n",
        "# hint: 在此用剛剛的 spm model 對 prediction_file 進行切斷詞\n",
        "# spm_model.encode(line, out_type=str)\n",
        "# output: ./DATA/rawdata/mono/mono.tok.en & mono.tok.zh\n",
        "#\n",
        "# hint: 在此用 fairseq 把這些檔案再 binarize\n",
        "# binpath = Path('./DATA/data-bin/synthetic')\n",
        "# src_dict_file = './DATA/data-bin/ted2020/dict.en.txt'\n",
        "# tgt_dict_file = src_dict_file\n",
        "# monopref = ./DATA/rawdata/mono/mono.tok # or whatever path after applying subword tokenization, w/o the suffix (.zh/.en)\n",
        "# if binpath.exists():\n",
        "#     print(binpath, \"exists, will not overwrite!\")\n",
        "# else:\n",
        "#     !python -m fairseq_cli.preprocess\\\n",
        "#         --source-lang 'zh'\\\n",
        "#         --target-lang 'en'\\\n",
        "#         --trainpref {monopref}\\\n",
        "#         --destdir {binpath}\\\n",
        "#         --srcdict {src_dict_file}\\\n",
        "#         --tgtdict {tgt_dict_file}\\\n",
        "#         --workers 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrbL-keo4raT"
      },
      "source": [
        "# 這裡用剛剛準備的檔案合併原先 ted2020 來生成最終 back-translation 的資料\n",
        "!cp -r ./DATA/data-bin/ted2020/ ./DATA/data-bin/ted2020_with_mono/\n",
        "\n",
        "!cp ./DATA/data-bin/synthetic/train.zh-en.zh.bin ./DATA/data-bin/ted2020_with_mono/train1.en-zh.zh.bin\n",
        "!cp ./DATA/data-bin/synthetic/train.zh-en.zh.idx ./DATA/data-bin/ted2020_with_mono/train1.en-zh.zh.idx\n",
        "!cp ./DATA/data-bin/synthetic/train.zh-en.en.bin ./DATA/data-bin/ted2020_with_mono/train1.en-zh.en.bin\n",
        "!cp ./DATA/data-bin/synthetic/train.zh-en.en.idx ./DATA/data-bin/ted2020_with_mono/train1.en-zh.en.idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_idPHxg4raT"
      },
      "source": [
        "### TODO: 重新訓練\n",
        "\n",
        "當已經產生新的資料集\n",
        "\n",
        "1. 將實驗的參數設定表(config)中的datadir改為新的資料集(\"./DATA/data-bin/ted2020_with_mono\")\n",
        "2. 將實驗的參數設定表(config)中的source_lang與target_lang設定還原(\"en\", \"zh\")\n",
        "3. 將實驗的參數設定表(config)中的savedir更改(ex. \"./checkpoints/rnn-bt\")\n",
        "4. 重新訓練"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HreySgiO4raT"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aURvtxfn4raU"
      },
      "source": [
        "1. <a name=ott2019fairseq></a>Ott, M., Edunov, S., Baevski, A., Fan, A., Gross, S., Ng, N., ... & Auli, M. (2019, June). fairseq: A Fast, Extensible Toolkit for Sequence Modeling. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations) (pp. 48-53).\n",
        "2. <a name=vaswani2017></a>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017, December). Attention is all you need. In Proceedings of the 31st International Conference on Neural Information Processing Systems (pp. 6000-6010).\n",
        "3. <a name=reimers-2020-multilingual-sentence-bert></a>Reimers, N., & Gurevych, I. (2020, November). Making Monolingual Sentence Embeddings Multilingual Using Knowledge Distillation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) (pp. 4512-4525).\n",
        "4. <a name=tiedemann2012parallel></a>Tiedemann, J. (2012, May). Parallel Data, Tools and Interfaces in OPUS. In Lrec (Vol. 2012, pp. 2214-2218).\n",
        "5. <a name=kudo-richardson-2018-sentencepiece></a>Kudo, T., & Richardson, J. (2018, November). SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations (pp. 66-71).\n",
        "6. <a name=sennrich-etal-2016-improving></a>Sennrich, R., Haddow, B., & Birch, A. (2016, August). Improving Neural Machine Translation Models with Monolingual Data. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 86-96).\n",
        "7. <a name=edunov-etal-2018-understanding></a>Edunov, S., Ott, M., Auli, M., & Grangier, D. (2018). Understanding Back-Translation at Scale. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (pp. 489-500).\n",
        "8. https://github.com/ajinkyakulkarni14/TED-Multilingual-Parallel-Corpus\n",
        "9. https://ithelp.ithome.com.tw/articles/10233122\n",
        "10. https://nlp.seas.harvard.edu/2018/04/03/attention.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGqGUivv4raU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}